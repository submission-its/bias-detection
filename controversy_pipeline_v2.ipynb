{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b7b1d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16b7b1d7",
    "outputId": "928b6d0b-06cb-4272-b8df-3d3c79f8fa56"
   },
   "outputs": [],
   "source": [
    "%pip install pymupdf together openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458d130",
   "metadata": {
    "id": "9458d130"
   },
   "outputs": [],
   "source": [
    "from together import Together\n",
    "from openai import OpenAI\n",
    "import fitz\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "client = Together(api_key=os.environ.get(\"TOGETHER_API_KEY\"))\n",
    "openai_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "MINER_MODEL = \"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\"  \n",
    "\n",
    "COUNCIL_MODELS = [\n",
    "    \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    \"openai/gpt-oss-120b\",\n",
    "    \"deepseek-ai/DeepSeek-V3.1\",\n",
    "    \"deepcogito/cogito-v2-1-671b\",\n",
    "    \"moonshotai/Kimi-K2-Thinking\",\n",
    "\n",
    "]\n",
    "\n",
    "META_JURY_MODEL = \"gpt-5.2\"  \n",
    "\n",
    "OUTPUT_FILE = \"results_corvinul.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d592bdcc",
   "metadata": {
    "id": "d592bdcc"
   },
   "outputs": [],
   "source": [
    "def get_total_pages(pdf_path: str) -> int:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    total_pages = len(doc)\n",
    "    doc.close()\n",
    "    return total_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c6b6c6",
   "metadata": {
    "id": "d4c6b6c6"
   },
   "outputs": [],
   "source": [
    "def pdf_page_to_base64(pdf_path: str, page_num: int, dpi: int = 200) -> str:\n",
    "    \"\"\"\n",
    "    Converts PDF page to PNG Base64.\n",
    "    Resizes to max 1280px for better text readability.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc[page_num]\n",
    "    \n",
    "    pix = page.get_pixmap(dpi=dpi)\n",
    "    \n",
    "    mode = \"RGBA\" if pix.alpha else \"RGB\"\n",
    "    img = Image.frombytes(mode, [pix.width, pix.height], pix.samples)\n",
    "    \n",
    "    if img.mode in (\"RGBA\", \"LA\", \"P\"):\n",
    "        background = Image.new(\"RGB\", img.size, (255, 255, 255))\n",
    "        if img.mode == \"P\":\n",
    "            img = img.convert(\"RGBA\")\n",
    "        background.paste(img, mask=img.split()[-1] if img.mode == \"RGBA\" else None)\n",
    "        img = background\n",
    "        \n",
    "    max_size = 1280\n",
    "    if max(img.size) > max_size:\n",
    "        ratio = max_size / max(img.size)\n",
    "        new_size = (int(img.width * ratio), int(img.height * ratio))\n",
    "        img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    buffered = io.BytesIO()\n",
    "    img.save(buffered, format=\"PNG\", optimize=True)\n",
    "    img_bytes = buffered.getvalue()\n",
    "    \n",
    "    return base64.b64encode(img_bytes).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f7f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clean_json(response_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts the first valid JSON object from a string, ignoring \n",
    "    <think> blocks, markdown wrappers, and conversational text.\n",
    "    \"\"\"\n",
    "    clean_text = re.sub(r\"```json\\s*\", \"\", response_text, flags=re.IGNORECASE)\n",
    "    clean_text = re.sub(r\"```\", \"\", clean_text)\n",
    "\n",
    "    clean_text = re.sub(r\"<think>.*?</think>\", \"\", clean_text, flags=re.DOTALL)\n",
    "\n",
    "    match = re.search(r'\\{.*\\}', clean_text, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        json_str = match.group(0)\n",
    "        try:\n",
    "            return json.loads(json_str, strict=False)\n",
    "        except json.JSONDecodeError:\n",
    "            return {\"error\": \"JSON Decode Error\", \"raw_content\": response_text}\n",
    "    else:\n",
    "        return {\"error\": \"No JSON found\", \"raw_content\": response_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7710604d",
   "metadata": {
    "id": "7710604d"
   },
   "outputs": [],
   "source": [
    "def analyze_image(prompt: str, image_b64: str, model: str) -> dict:\n",
    "    \"\"\"Calls vision model with image and returns JSON response.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Analyze this textbook page:\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_b64}\"}}\n",
    "            ]}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    result_text = response.choices[0].message.content.strip()\n",
    "    return json.loads(result_text, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0495c134",
   "metadata": {
    "id": "0495c134"
   },
   "outputs": [],
   "source": [
    "def analyze_text(prompt: str, content: str, model: str, **kwargs) -> dict:\n",
    "    \"\"\"\n",
    "    Calls text model and extracts JSON, handling thinking models.\n",
    "    Function supports extra parameters like max_tokens.\n",
    "    \"\"\"\n",
    "    if \"max_tokens\" not in kwargs:\n",
    "        if \"thinking\" in model.lower() or \"r1\" in model.lower():\n",
    "            kwargs[\"max_tokens\"] = 16000 \n",
    "        else:\n",
    "            kwargs[\"max_tokens\"] = 4096\n",
    "\n",
    "    result_text = \"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": content}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            **kwargs \n",
    "        )\n",
    "        result_text = response.choices[0].message.content.strip()\n",
    "    except Exception:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": prompt},\n",
    "                    {\"role\": \"user\", \"content\": content}\n",
    "                ],\n",
    "                **kwargs \n",
    "            )\n",
    "            result_text = response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"API Error: {str(e)}\"}\n",
    "    \n",
    "    if not result_text:\n",
    "        return {\"error\": \"Empty response from model\", \"raw_response\": \"\"}\n",
    "\n",
    "    data = extract_clean_json(result_text)\n",
    "    if isinstance(data, dict):\n",
    "        data[\"_raw_response\"] = result_text\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38cf8f1b",
   "metadata": {
    "id": "38cf8f1b"
   },
   "outputs": [],
   "source": [
    "MINER_PROMPT = \"\"\"You are an expert Educational Auditor performing a preliminary bias scan of a Romanian history textbook for controversial content.\n",
    "\n",
    "You will receive a BATCH of pages. Analyze them TOGETHER.\n",
    "\n",
    "### YOUR CORE MISSION\n",
    "Identify **ANY passage that could influence a student's historical interpretation** in a non-neutral way.\n",
    "\n",
    "This includes:\n",
    "- Subtle framing choices\n",
    "- Value-laden adjectives\n",
    "- Selective emphasis or silence\n",
    "- Normalization of one perspective\n",
    "- Assumptions presented as facts\n",
    "- National, ethnic, political, or moral alignment cues\n",
    "\n",
    "You are NOT deciding whether the content is definitively biased or wrong.\n",
    "You are identifying **POTENTIAL POINTS OF INTERPRETIVE INFLUENCE** that merit further review.\n",
    "\n",
    "### CRITICAL RULE: VERBATIM QUOTE EXTRACTION\n",
    "When you fill the \"quotes\" field in the JSON, you must act as a strict OCR engine:\n",
    "1. **EXACT MATCH:** Copy the text **exactly** as it appears in the image. Do not paraphrase, summarize, or fix typos.\n",
    "2. **NO TRANSLATION:** If the text is in Romanian, quote it in Romanian.\n",
    "3. **PRESERVE STYLE:** Keep the original punctuation and diacritics if visible.\n",
    "4. **CONTEXT:** If the biased text is part of a longer sentence, include enough context so the meaning is clear.\n",
    "\n",
    "### EVIDENTIARY COMPLETENESS REQUIREMENT\n",
    "\n",
    "All interpretive concerns must be supported by direct quotations.\n",
    "\n",
    "In the \"quotes\" field:\n",
    "- Include EVERY passage that materially contributed to identifying the concern.\n",
    "- If the issue depends on multiple sentences, sections, or contrasting passages, include each relevant excerpt as a separate quote entry.\n",
    "- Do NOT rely on unquoted text to justify your explanation.\n",
    "- Do NOT quote only a fragment if the broader sentence or paragraph materially affects meaning.\n",
    "- The explanation must be fully supported by the quoted text.\n",
    "- Copy the text **exactly** as it appears in the image. Do not paraphrase, summarize, or fix typos.\n",
    "- If the text is in Romanian, quote it in Romanian.\n",
    "- Keep the original punctuation and diacritics if visible.\n",
    "\n",
    "If an idea influenced your concern but is not directly quoted, you must add the relevant text to the quotes field.\n",
    "\n",
    "\n",
    "### AUTHOR VS. SOURCE AWARENESS\n",
    "\n",
    "History textbooks often include quotations from earlier periods that reflect the language, values, or prejudices of their time.\n",
    "\n",
    "IMPORTANT:\n",
    "- Offensive or exclusionary language appearing in a **Primary Source** does NOT automatically constitute textbook bias.\n",
    "- Do NOT treat historical quotations as problematic merely for reflecting past attitudes.\n",
    "\n",
    "Your task is to:\n",
    "- Correctly identify whether the language comes from the **Textbook Author** or from a **Historical Source**\n",
    "- Flag the passage ONLY if the way the quote is used (selection, emphasis, framing, or lack of context) could influence interpretation\n",
    "\n",
    "### OUTPUT FORMAT (JSON ONLY)\n",
    "You may use multi-step reasoning internally.\n",
    "Return a JSON object with a list of issues.\n",
    "{\n",
    "  \"issues\": [\n",
    "    {\n",
    "      \"controversy\": \"Short title\",\n",
    "      \"source_type\": \"<TEXTBOOK_NARRATIVE|PRIMARY_SOURCE_USAGE>\",\n",
    "      \"quotes\": [\n",
    "        {\"text\": \"PASTE EXACT TEXT FROM IMAGE HERE\", \"page_offset\": 0}\n",
    "      ],\n",
    "      \"explanation\": \"Explain why this passage could influence interpretation or raise a potential concern. Avoid definitive judgments.\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "If no issues found, return:\n",
    "{\"issues\": []}\n",
    "\"\"\"\n",
    "\n",
    "COUNCIL_PROMPT = \"\"\"You are an expert Educational Historian auditing a Romanian high school history textbook.\n",
    "\n",
    "### INPUT DATA\n",
    "- **CLAIM:** {controversy}\n",
    "- **CONTEXT TYPE:** {source_type} (Is this the Author's Narrative or a Primary Source?)\n",
    "- **EVIDENCE:** {quotes}\n",
    "- **MINER'S NOTE:** {explanation}\n",
    "\n",
    "You are encouraged to assign low severity or dismiss concerns when appropriate.\n",
    "\n",
    "### STEP 1: Attribution Assessment\n",
    "Determine whether the interpretive concern arises from:\n",
    "- The **Textbook Author's Narrative**, or\n",
    "- The **Use of a Primary Source**\n",
    "\n",
    "If the passage is a Primary Source:\n",
    "- Assess whether it is contextualized or neutrally presented\n",
    "- Neutral presentation generally corresponds to low severity\n",
    "\n",
    "### STEP 2: Category Classification\n",
    "Select ONE category from the list below that best describes the primary interpretive concern.\n",
    "You MUST use one of these exact strings — do not invent new category names.\n",
    "\n",
    "**Language & Framing**\n",
    "- Linguistic Tone\n",
    "- Narrative Framing\n",
    "- Moral Loading\n",
    "\n",
    "**Perspective & Representation**\n",
    "- Perspective Limitation\n",
    "- Group Representation\n",
    "- Agency Attribution\n",
    "\n",
    "**Structure & Emphasis**\n",
    "- Selection Bias\n",
    "- Omission / Underdevelopment\n",
    "- Asymmetrical Detail\n",
    "\n",
    "**Source Handling**\n",
    "- Primary Source Framing\n",
    "- Attribution Ambiguity\n",
    "- Source Selection Bias\n",
    "\n",
    "**Interpretation & Pedagogy**\n",
    "- Teleological Narrative\n",
    "- National or Cultural Centering\n",
    "- Presentism\n",
    "\n",
    "### STEP 3: Severity Assessment (7-Point Scale)\n",
    "- **1: Neutral / Pedagogically Sound**\n",
    "- **2: Negligible Framing**\n",
    "- **3: Minor Imbalance**\n",
    "- **4: Moderate Bias**\n",
    "- **5: Significant Distortion**\n",
    "- **6: Severe Misrepresentation**\n",
    "- **7: Educational Harm / Propaganda**\n",
    "\n",
    "### STEP 4: Confidence\n",
    "Rate your confidence from 0.0 (uncertain) to 1.0 (certain).\n",
    "\n",
    "### OUTPUT FORMAT (JSON ONLY)\n",
    "{{\n",
    "  \"attribution\": \"<TEXTBOOK_NARRATIVE|PRIMARY_SOURCE_USAGE>\",\n",
    "  \"category\": \"<one exact category string from the Step 2 list>\",\n",
    "  \"severity\": <integer 1-7>,\n",
    "  \"confidence\": <number 0.0-1.0>,\n",
    "  \"reasoning\": \"Concise, outcome-focused justification explaining the assessment.\"\n",
    "}}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "META_JURY_PROMPT = \"\"\"\n",
    "You are the Chief Juror of an Educational Audit Council.\n",
    "\n",
    "Your role is to synthesize multiple expert evaluations into a single authoritative final verdict.\n",
    "You must exercise independent judgment and produce your own reasoned conclusion.\n",
    "\n",
    "### YOUR GOALS\n",
    "1. Read all juror inputs \n",
    "2. Produce a final severity score and system-level confidence\n",
    "3. Flag cases requiring human review when appropriate\n",
    "\n",
    "### INPUT DATA\n",
    "**Original Controversy:** {controversy}  \n",
    "**Source Type:** {source_type}  \n",
    "**Evidence Quotes:** {quotes}  \n",
    "**Miner's Note:** {explanation}  \n",
    "**Individual Juror Evaluations:** {juror_evaluations}\n",
    "\n",
    "### ALLOWED TAXONOMY\n",
    "The final_category MUST be one of the following exact strings:\n",
    "[Linguistic Tone, Narrative Framing, Moral Loading, Perspective Limitation, Group Representation, Agency Attribution, Selection Bias, Omission / Underdevelopment, Asymmetrical Detail, Primary Source Framing, Attribution Ambiguity, Source Selection Bias, Teleological Narrative, National or Cultural Centering, Presentism, INVALID_INPUT]\n",
    "\n",
    "### DECISION LOGIC\n",
    "Read all juror inputs carefully. Make your own independent judgment — the position best supported by the evidence wins, regardless of how many jurors hold it.\n",
    "\n",
    "- **Human Review Flag:** Flag for human review when high-confidence jurors meaningfully disagree on severity.\n",
    "\n",
    "### OUTPUT FORMAT (JSON ONLY)\n",
    "{{\n",
    "  \"final_attribution\": \"<TEXTBOOK_NARRATIVE|PRIMARY_SOURCE_USAGE>\",\n",
    "  \"final_category\": \"<one exact category string from the ALLOWED TAXONOMY>\",\n",
    "  \"final_severity\": <integer 1-7>,\n",
    "  \"system_confidence\": <number 0.0-1.0>,\n",
    "  \"flag_for_human_review\": <true|false>,\n",
    "  \"synthesis_summary\": \"Concise summary of your reasoning and the rationale for the final verdict.\",\n",
    "  \"variance_note\": \"If flagged for review, briefly describe the nature of the disagreement. If not flagged, set to empty string.\"\n",
    "}}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f730cc37",
   "metadata": {
    "id": "f730cc37"
   },
   "outputs": [],
   "source": [
    "def run_miner_batch(pdf_path: str, start_page: int, num_pages: int = 10, debug: bool = False) -> list:\n",
    "    \"\"\"Analyzes multiple PDF pages together for controversial content.\"\"\"\n",
    "    if debug:\n",
    "        print(f\"  [miner] pages {start_page+1}–{start_page+num_pages} | model: {MINER_MODEL.split('/')[-1]}\")\n",
    "\n",
    "    message_content = [{\"type\": \"text\", \"text\": \"Analyze these textbook pages together as a batch:\"}]\n",
    "    total_size = 0\n",
    "\n",
    "    for offset in range(num_pages):\n",
    "        page_num = start_page + offset\n",
    "        image_b64 = pdf_page_to_base64(pdf_path, page_num)\n",
    "        total_size += len(image_b64)\n",
    "        message_content.append(\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_b64}\"}}\n",
    "        )\n",
    "\n",
    "    if debug:\n",
    "        avg_size = total_size // num_pages\n",
    "        print(f\"  [miner] {num_pages} pages encoded | avg size: {avg_size:,} chars\")\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MINER_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": MINER_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": message_content},\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    result_text = response.choices[0].message.content.strip()\n",
    "\n",
    "    result = json.loads(result_text, strict=False)\n",
    "\n",
    "    if isinstance(result, dict) and \"issues\" in result:\n",
    "        candidates = result[\"issues\"]\n",
    "    elif isinstance(result, list):\n",
    "        candidates = result\n",
    "    else:\n",
    "        candidates = [result]\n",
    "\n",
    "    for item in candidates:\n",
    "        if \"source_type\" not in item:\n",
    "            item[\"source_type\"] = \"TEXTBOOK_NARRATIVE\"\n",
    "        if \"quotes\" in item:\n",
    "            for quote in item[\"quotes\"]:\n",
    "                if isinstance(quote, dict):\n",
    "                    page_offset = quote.get(\"page_offset\", 0)\n",
    "                    quote[\"page\"] = start_page + page_offset + 1\n",
    "\n",
    "    if debug:\n",
    "        print(f\"  [miner]: {len(candidates)} issue(s) found\")\n",
    "\n",
    "    return candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lhJqcFhj4S3u",
   "metadata": {
    "id": "lhJqcFhj4S3u"
   },
   "outputs": [],
   "source": [
    "def run_council(controversy: str, quotes: list, explanation: str, source_type: str = \"Unknown\", debug: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Runs council of models sequentially, then Meta-Jury synthesis.\n",
    "    \"\"\"\n",
    "    council_results = []\n",
    "\n",
    "    formatted_quotes = []\n",
    "    for q in quotes:\n",
    "        text = q.get('text', '') if isinstance(q, dict) else str(q)\n",
    "        formatted_quotes.append(f\"- {text}\")\n",
    "\n",
    "    prompt = COUNCIL_PROMPT.format(\n",
    "        controversy=controversy,\n",
    "        source_type=source_type,\n",
    "        quotes=\"\\n\".join(formatted_quotes),\n",
    "        explanation=explanation\n",
    "    )\n",
    "\n",
    "    MAX_RETRIES = 3\n",
    "\n",
    "    for model in COUNCIL_MODELS:\n",
    "        model_name = model.split('/')[-1]\n",
    "        if debug:\n",
    "            print(f\"  [council] querying {model_name}...\")\n",
    "\n",
    "        result = None\n",
    "        valid = False\n",
    "\n",
    "        for attempt in range(MAX_RETRIES):\n",
    "            result = analyze_text(prompt, \"\", model)\n",
    "\n",
    "            has_severity = \"severity\" in result\n",
    "            has_confidence = \"confidence\" in result\n",
    "            has_category = \"category\" in result\n",
    "            has_reasoning = \"reasoning\" in result and bool(result.get(\"reasoning\", \"\").strip())\n",
    "\n",
    "            severity_valid = False\n",
    "            if has_severity:\n",
    "                try:\n",
    "                    test_severity = float(result.get(\"severity\", -1))\n",
    "                    severity_valid = 1 <= test_severity <= 7\n",
    "                except Exception:\n",
    "                    severity_valid = False\n",
    "\n",
    "            confidence_valid = False\n",
    "            if has_confidence:\n",
    "                try:\n",
    "                    test_confidence = float(result.get(\"confidence\", -1))\n",
    "                    confidence_valid = 0 <= test_confidence <= 1\n",
    "                except Exception:\n",
    "                    confidence_valid = False\n",
    "\n",
    "            if has_severity and has_confidence and has_category and has_reasoning and severity_valid and confidence_valid:\n",
    "                valid = True\n",
    "                if debug and attempt > 0:\n",
    "                    print(f\"  [council] {model_name} passed on attempt {attempt + 1}\")\n",
    "                break\n",
    "\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                if debug:\n",
    "                    print(f\"  [council] {model_name} retry {attempt + 1}/{MAX_RETRIES} \"\n",
    "                          f\"(severity={severity_valid}, confidence={confidence_valid}, \"\n",
    "                          f\"category={has_category}, reasoning={has_reasoning})\")\n",
    "            else:\n",
    "                print(f\"  {model_name} dropped (failed validation after {MAX_RETRIES} attempts)\")\n",
    "\n",
    "        if not valid:\n",
    "            continue\n",
    "\n",
    "        attribution = result.get(\"attribution\", \"UNKNOWN\")\n",
    "        category = result.get(\"category\", \"Unknown\")\n",
    "        reasoning = result.get(\"reasoning\", \"\")\n",
    "\n",
    "        raw_severity = result.get(\"severity\", 4)\n",
    "        severity = 4\n",
    "        try:\n",
    "            if isinstance(raw_severity, (int, float)):\n",
    "                severity = float(raw_severity)\n",
    "            elif isinstance(raw_severity, str):\n",
    "                s = str(raw_severity).strip()\n",
    "                if \"-\" in s:\n",
    "                    parts = s.split(\"-\")\n",
    "                    nums = [float(p) for p in parts if p.strip().replace('.', '', 1).isdigit()]\n",
    "                    if len(nums) >= 2:\n",
    "                        severity = sum(nums[:2]) / 2\n",
    "                    elif len(nums) == 1:\n",
    "                        severity = nums[0]\n",
    "                else:\n",
    "                    match = re.search(r\"(\\d+(\\.\\d+)?)\", s)\n",
    "                    if match:\n",
    "                        severity = float(match.group(1))\n",
    "        except Exception:\n",
    "            severity = 4\n",
    "        severity = max(1, min(7, severity))\n",
    "\n",
    "        raw_confidence = result.get(\"confidence\", 0.5)\n",
    "        confidence = 0.5\n",
    "        try:\n",
    "            if isinstance(raw_confidence, (int, float)):\n",
    "                confidence = float(raw_confidence)\n",
    "            elif isinstance(raw_confidence, str):\n",
    "                s = str(raw_confidence).strip()\n",
    "                match = re.search(r\"(\\d+(\\.\\d+)?)\", s)\n",
    "                if match:\n",
    "                    confidence = float(match.group(1))\n",
    "        except Exception:\n",
    "            confidence = 0.5\n",
    "        confidence = max(0, min(1, confidence))\n",
    "\n",
    "        if debug:\n",
    "            print(f\"  [council]: {model_name}: {severity}/7, conf={confidence:.2f}, cat={category}\")\n",
    "\n",
    "        council_results.append({\n",
    "            \"model\": model_name,\n",
    "            \"attribution\": attribution,\n",
    "            \"category\": category,\n",
    "            \"severity\": severity,\n",
    "            \"confidence\": confidence,\n",
    "            \"reasoning\": reasoning\n",
    "        })\n",
    "\n",
    "    if not council_results:\n",
    "        print(f\"  All jurors dropped: returning fallback result\")\n",
    "        return {\n",
    "            \"final_severity\": 1,\n",
    "            \"system_confidence\": 0.0,\n",
    "            \"final_category\": \"Unknown\",\n",
    "            \"final_attribution\": \"UNKNOWN\",\n",
    "            \"flag_for_human_review\": True,\n",
    "            \"synthesis_reasoning\": \"All jurors failed validation. Manual review required.\",\n",
    "            \"variance_analysis\": \"No valid juror responses.\",\n",
    "            \"individual_jurors\": []\n",
    "        }\n",
    "\n",
    "    juror_evaluations = []\n",
    "    for idx, jr in enumerate(council_results, 1):\n",
    "        juror_evaluations.append(\n",
    "            f\"**Juror {idx} ({jr['model']}):**\\n\"\n",
    "            f\"- Category: {jr['category']}\\n\"\n",
    "            f\"- Severity: {jr['severity']}/7\\n\"\n",
    "            f\"- Confidence: {jr['confidence']:.2f}\\n\"\n",
    "            f\"- Attribution: {jr['attribution']}\\n\"\n",
    "            f\"- Reasoning: {jr['reasoning']}\\n\"\n",
    "        )\n",
    "\n",
    "    meta_prompt = META_JURY_PROMPT.format(\n",
    "        controversy=controversy,\n",
    "        source_type=source_type,\n",
    "        quotes=\"\\n\".join(formatted_quotes),\n",
    "        explanation=explanation,\n",
    "        juror_evaluations=\"\\n\".join(juror_evaluations)\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        print(f\"  [meta-jury] synthesizing {len(council_results)} juror(s) via {META_JURY_MODEL}...\")\n",
    "\n",
    "    try:\n",
    "        meta_response = openai_client.chat.completions.create(\n",
    "            model=META_JURY_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": meta_prompt},\n",
    "                {\"role\": \"user\", \"content\": \"Synthesize the juror evaluations and provide your final verdict.\"}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "        meta_text = meta_response.choices[0].message.content.strip()\n",
    "        meta_result = json.loads(meta_text, strict=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Meta-Jury unavailable: {str(e)}\"\n",
    "        print(f\"  ✗ Meta-Jury failed: {str(e)}\")\n",
    "        return {\n",
    "            \"final_severity\": None,\n",
    "            \"system_confidence\": None,\n",
    "            \"final_category\": None,\n",
    "            \"final_attribution\": None,\n",
    "            \"flag_for_human_review\": True,\n",
    "            \"synthesis_reasoning\": error_msg,\n",
    "            \"variance_analysis\": \"Meta-Jury call failed. No verdict produced.\",\n",
    "            \"individual_jurors\": council_results\n",
    "        }\n",
    "\n",
    "    if debug:\n",
    "        flagged = meta_result.get('flag_for_human_review')\n",
    "        print(f\"  [meta-jury]: {meta_result.get('final_severity')}/7, \"\n",
    "              f\"conf={meta_result.get('system_confidence', 0):.2f}\"\n",
    "              + (\" flagged\" if flagged else \"\"))\n",
    "\n",
    "    return {\n",
    "        \"final_severity\": meta_result.get(\"final_severity\"),\n",
    "        \"system_confidence\": meta_result.get(\"system_confidence\"),\n",
    "        \"final_category\": meta_result.get(\"final_category\"),\n",
    "        \"final_attribution\": meta_result.get(\"final_attribution\"),\n",
    "        \"flag_for_human_review\": meta_result.get(\"flag_for_human_review\", False),\n",
    "        \"synthesis_reasoning\": meta_result.get(\"synthesis_summary\", meta_result.get(\"synthesis_reasoning\", \"\")),\n",
    "        \"variance_analysis\": meta_result.get(\"variance_note\", meta_result.get(\"variance_analysis\", \"\")),\n",
    "        \"individual_jurors\": council_results\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6121b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4e6121b9",
    "outputId": "16ef7165-ffa2-417d-d8d8-f609182fcc85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chapter-based analysis of: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "Processing 5 pages per batch\n",
      "============================================================\n",
      "Total pages: 144\n",
      "\n",
      "\n",
      "============================================================\n",
      "BATCH 1: Pages 1-5\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 1 to 5\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 1:\n",
      "[DEBUG]   - Base64 length: 1,075,396 chars\n",
      "[DEBUG] Added page 2:\n",
      "[DEBUG]   - Base64 length: 7,412 chars\n",
      "[DEBUG] Added page 3:\n",
      "[DEBUG]   - Base64 length: 124,264 chars\n",
      "[DEBUG] Added page 4:\n",
      "[DEBUG]   - Base64 length: 390,108 chars\n",
      "[DEBUG] Added page 5:\n",
      "[DEBUG]   - Base64 length: 717,664 chars\n",
      "[DEBUG] Average image size: 462,968 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 746 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Nationalistic Lyrics\",\n",
      "      \"source_type\": \"PRIMARY_SOURCE_USAGE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Deșteaptă-te, române!\",\n",
      "          \"page_offset\": 0\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Dar noi, pătrunși la suflet de sântă libertate, Jurăm că vom da mâna, să fim pururea frați!\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The inclusion of 'Deșteaptă-te, române!' with its nationalistic and potentially militaristic lyrics could be seen as promoting a specific national identity or political ideology. While this is a historical source, its presentation without critical context may influence students' interpretation of historical nationalism.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 1 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 1 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Nationalistic Lyrics ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Nationalistic Lyrics\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: PRIMARY_SOURCE_USAGE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Primary Source Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.78, Category=Primary Source Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.83, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Primary Source Framing, Confidence: 0.83\n",
      "\n",
      "============================================================\n",
      "BATCH 2: Pages 6-10\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 6 to 10\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 6:\n",
      "[DEBUG]   - Base64 length: 412,180 chars\n",
      "[DEBUG] Added page 7:\n",
      "[DEBUG]   - Base64 length: 1,282,912 chars\n",
      "[DEBUG] Added page 8:\n",
      "[DEBUG]   - Base64 length: 1,250,748 chars\n",
      "[DEBUG] Added page 9:\n",
      "[DEBUG]   - Base64 length: 1,325,928 chars\n",
      "[DEBUG] Added page 10:\n",
      "[DEBUG]   - Base64 length: 1,214,724 chars\n",
      "[DEBUG] Average image size: 1,097,298 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 3000 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in historical interpretation\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Dacă primii ani ai secolului XX sunt dominați de o Europă model al civilizației universale, ce a urmat poate fi considerat, potrivit expresiei istoricului englez Eric Hobsbawn, „o epocă a catastrofei” (1914-1945) urmată de „o epocă de aur” (1945-1971/1973), căreia i-a succedat o epocă de descompunere și criză punctată în 1989 de prăbușirea regimurilor comuniste din Estul Europei.\",\n",
      "          \"page_offset\": 2\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The use of Eric Hobsbawn's expression 'o epocă a catastrofei' (an age of catastrophe) for the period 1914-1945 could be seen as framing the historical events of that period in a negative light, potentially influencing the student's interpretation of the historical significance of World War I and II.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in historical interpretation\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Construcția Europei nu se va face ușor, nici în linii generale; acest lucru se va realiza prin acte mai concrete mai întai de toate, prin crearea unei stări de solidaritate a faptelor.\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The quote from Robert Schuman's declaration presents a positive view of European integration, potentially influencing students' perception of the European unification process as inherently positive and necessary.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in primary source usage\",\n",
      "      \"source_type\": \"PRIMARY_SOURCE_USAGE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Peisajul englez posedă o calitate pe care peisajele altor națiuni, inevitabil nu reușesc să o aibă. Aceastea este, cred eu, de o calitate ce se face remarcată oricărui observator obiectiv iar ea exprimată de termenul mărime.\",\n",
      "          \"page_offset\": 2\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The inclusion of Kazuo Ishiguro's quote about the English landscape having a unique quality could be seen as presenting a subjective view on national characteristics, potentially influencing students' perceptions of different cultures.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in historical interpretation\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"În contextul afirmării ideilor naționale, în Europa se produce însă revirementul antisemitismului. Ca reacție a acestuia ia ființă naționalismul evreiesc, sionismul, al cărui părinte este Theodor Herzl.\",\n",
      "          \"page_offset\": 3\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The mention of the rise of antisemitism and the emergence of Zionism as a reaction could be seen as framing these historical developments in a particular context, potentially influencing students' understanding of the complex historical and political factors involved.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 4 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 4 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in historical interpretation ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in historical interpretation\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Narrative Framing, Confidence: 0.86\n",
      "\n",
      "--- Issue 2: Potential bias in historical interpretation ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in historical interpretation\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=2.0/7, Confidence=0.80, Category=Neutral Presentation\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['final{', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.88, Category=Primary Source Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=1/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking failed all 3 attempts — DROPPING from council\n",
      "  ✗ Kimi-K2-Thinking dropped (failed validation after 3 attempts)\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 4\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Primary Source Framing, Confidence: 0.86\n",
      "\n",
      "--- Issue 3: Potential bias in primary source usage ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in primary source usage\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: PRIMARY_SOURCE_USAGE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.70, Category=Primary Source Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b succeeded on attempt 2\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=National or Cultural Centering\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Source Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.90, Category=Source Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.70, Category=Primary Source Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.84, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Primary Source Framing, Confidence: 0.84\n",
      "\n",
      "--- Issue 4: Potential bias in historical interpretation ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in historical interpretation\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Agency Attribution\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.82, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.82\n",
      "\n",
      "============================================================\n",
      "BATCH 3: Pages 11-15\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 11 to 15\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 11:\n",
      "[DEBUG]   - Base64 length: 1,317,404 chars\n",
      "[DEBUG] Added page 12:\n",
      "[DEBUG]   - Base64 length: 1,226,176 chars\n",
      "[DEBUG] Added page 13:\n",
      "[DEBUG]   - Base64 length: 1,397,256 chars\n",
      "[DEBUG] Added page 14:\n",
      "[DEBUG]   - Base64 length: 1,204,252 chars\n",
      "[DEBUG] Added page 15:\n",
      "[DEBUG]   - Base64 length: 1,277,808 chars\n",
      "[DEBUG] Average image size: 1,284,579 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 2792 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in historical interpretation\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Secolul al XX-lea rămâne în istoria umanității ca o perioadă în care au avut loc două mari catastrofe, două mari conflagrații mondiale.\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The statement frames the 20th century solely as a period of 'two great catastrophes' and 'two great world wars,' which could influence students to view the century negatively without acknowledging positive developments.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Value-laden description of historical events\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Spre finele secolului al XX-lea popoarele din Estul Europei se vor angaja și ele pe calea integrării euroatlantice.\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The use of 'se vor angaja' (will engage) implies a positive direction towards 'euroatlantic integration,' potentially presenting this path as inherently desirable without discussing potential drawbacks.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Selective emphasis on negative aspects of totalitarian regimes\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"ideologiile totalitare, atât cea de stânga, comunismul, cât și cea de dreapta, nazismul\",\n",
      "          \"page_offset\": 2\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The mention of totalitarian ideologies focuses on their negative aspects without providing a balanced view of their historical context or complexities.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Assumptions about European unity and diversity\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Unitatea Europei în secolul al XX-lea, un subiect complex și controversat\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"Describing European unity as 'complex and controversial' may influence students to consider it primarily through the lens of controversy without fully exploring its positive aspects or historical context.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Presentation of cultural diversity\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Diversitatea în Europa secolului al XX-lea înseamnă manifestarea etnicităților, a religiilor și a unor culturi cu trăsături caracteristice.\",\n",
      "          \"page_offset\": 3\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The emphasis on 'manifestarea etnicităților, a religiilor și a unor culturi' could be seen as promoting a particular view of diversity without fully addressing potential challenges or conflicts associated with it.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 5 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 5 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in historical interpretation ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in historical interpretation\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b succeeded on attempt 2\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.92, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=Perspective Limitation\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.84, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.84\n",
      "\n",
      "--- Issue 2: Value-laden description of historical events ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Value-laden description of historical events\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.95, Category=Moral Loading\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Linguistic Tone\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=Teleological Narrative\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=Teleological Narrative\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.84, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Teleological Narrative, Confidence: 0.84\n",
      "\n",
      "--- Issue 3: Selective emphasis on negative aspects of totalitarian regimes ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective emphasis on negative aspects of totalitarian regimes\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 3\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.70, Category=Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.75, Category=Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=5.0/7, Confidence=0.75, Category=Omission / Underdevelopment\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.72, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Omission / Underdevelopment, Confidence: 0.72\n",
      "\n",
      "--- Issue 4: Assumptions about European unity and diversity ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Assumptions about European unity and diversity\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Language & Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.88, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.80, Category=Linguistic Tone\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.86\n",
      "\n",
      "--- Issue 5: Presentation of cultural diversity ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Presentation of cultural diversity\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.87, Category=Group Representation\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Omission / Underdevelopment\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.80, Category=Omission / Underdevelopment\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.82, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Omission / Underdevelopment, Confidence: 0.82\n",
      "\n",
      "============================================================\n",
      "BATCH 4: Pages 16-20\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 16 to 20\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 16:\n",
      "[DEBUG]   - Base64 length: 1,148,496 chars\n",
      "[DEBUG] Added page 17:\n",
      "[DEBUG]   - Base64 length: 1,349,000 chars\n",
      "[DEBUG] Added page 18:\n",
      "[DEBUG]   - Base64 length: 1,274,864 chars\n",
      "[DEBUG] Added page 19:\n",
      "[DEBUG]   - Base64 length: 1,301,028 chars\n",
      "[DEBUG] Added page 20:\n",
      "[DEBUG]   - Base64 length: 1,174,244 chars\n",
      "[DEBUG] Average image size: 1,249,526 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 4095 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in presenting historical events\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Punerea în aplicare, în anul 1948, a Planului Marshall menit să relanseze economia statelor europene crează o primă solidaritate comercială și monetară în inima unei Europe devastate de distrugerile provocate de cel de-al doilea război mondial.\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The passage presents the Marshall Plan as a positive initiative without discussing potential criticisms or alternative perspectives, which could influence the student's interpretation of its impact.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Selective emphasis on certain historical figures\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Părinții fondatori ai Europei unite: Miniștrii de externe ai Franței, Germaniei și Italiei și ai celor trei țări care formează Beneluxul (Belgia, Olanda și Luxemburgul) cad de acord asupra extinderii colaborării dintre statele occidentale.\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The text highlights specific individuals and countries as 'founding fathers' of European unity, potentially creating a biased narrative by selectively emphasizing their roles.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Value-laden language in historical context\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Istoria a demonstrat că soluția cooperării internaționale aplicată și perfecționată în cadrul Comunității Economice Europene a fost o soluție de succes, dovadă fiind evoluția economică pozitivă a statelor membre.\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The use of the phrase 'soluție de succes' (solution of success) could be seen as value-laden, as it presents the outcome in a positive light without acknowledging potential drawbacks.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Framing of historical events\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Încă din 12 septembrie 1946, în timp ce se elabora programul american de redresare a Europei, într-un discurs rostit la Universitatea din Zürich Winston Churchill cheamă la înființarea 'Statelor Unite ale Europei'.\",\n",
      "          \"page_offset\": 2\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The mention of Winston Churchill's call for 'United States of Europe' is presented as a significant event, potentially framing the idea of European unity as historically rooted in Western political thought.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Assumptions presented as facts\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Pentru menținerea și pentru realizarea pe mai departe a idealurilor de pace, de cooperare internațională și de promovare a drepturilor omului, a valorilor democrației și ale statului de drept, statele europene nu pot găsi o altă soluție decât întărirea unității care să garanteze demnitatea cetățenilor lor.\",\n",
      "          \"page_offset\": 3\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The statement assumes that further European unity is the only solution for maintaining peace and promoting democracy, presenting this as a fact rather than an interpretation.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Selective presentation of historical perspectives\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"În condițiile în care puterea din lumea de astăzi se deplasează din lumea dezvoltată spre alte zone și în care procesul de globalizare înaintează cu pași rapizi, interesele statelor europene le impun acestora strategii politice realiste.\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The passage implies that European states need 'realistic political strategies' without discussing what these strategies entail or alternative approaches, potentially influencing the student's perspective on European political strategies.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 6 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 6 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in presenting historical events ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in presenting historical events\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Perspective & Representation\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.92, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 3\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Perspective Limitation\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.85, Category=Omission / Underdevelopment\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=PerspectiveLimitation\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.87, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Omission / Underdevelopment, Confidence: 0.87\n",
      "\n",
      "--- Issue 2: Selective emphasis on certain historical figures ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective emphasis on certain historical figures\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.88, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.75, Category=Omission / Underdevelopment\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.83, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Selection Bias, Confidence: 0.83\n",
      "\n",
      "--- Issue 3: Value-laden language in historical context ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Value-laden language in historical context\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Language & Framing, Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.90, Category=Moral Loading\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Linguistic Tone\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.90, Category=Moral Loading\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.88, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Moral Loading, Confidence: 0.88\n",
      "\n",
      "--- Issue 4: Framing of historical events ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Framing of historical events\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Asymmetrical Detail\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.84, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Narrative Framing, Confidence: 0.84\n",
      "\n",
      "--- Issue 5: Assumptions presented as facts ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Assumptions presented as facts\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Interpretation & Pedagogy\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.85, Category=Teleological Narrative\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.90, Category=Perspective Limitation\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.90, Category=Perspective Limitation\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.84, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Teleological Narrative, Confidence: 0.84\n",
      "\n",
      "--- Issue 6: Selective presentation of historical perspectives ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective presentation of historical perspectives\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Perspective Limitation\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Perspective Limitation\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.85, Category=Omission / Underdevelopment\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Perspective Limitation\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.83, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Perspective Limitation, Confidence: 0.83\n",
      "\n",
      "============================================================\n",
      "BATCH 5: Pages 21-25\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 21 to 25\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 21:\n",
      "[DEBUG]   - Base64 length: 1,136,724 chars\n",
      "[DEBUG] Added page 22:\n",
      "[DEBUG]   - Base64 length: 1,142,612 chars\n",
      "[DEBUG] Added page 23:\n",
      "[DEBUG]   - Base64 length: 1,317,072 chars\n",
      "[DEBUG] Added page 24:\n",
      "[DEBUG]   - Base64 length: 1,197,960 chars\n",
      "[DEBUG] Added page 25:\n",
      "[DEBUG]   - Base64 length: 1,338,900 chars\n",
      "[DEBUG] Average image size: 1,226,653 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 4921 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\"issues\": [\n",
      "  {\n",
      "    \"controversy\": \"Potential bias in historical interpretation\",\n",
      "    \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "    \"quotes\": [\n",
      "      {\"text\": \"Tulburările internaționale care au loc între căderea zidului Berlinului și dezmembrarea URSS, în loc să paralizeze procesul de integrare început la Roma în 1957, ii dau un impuls suplimentar și ii adaugă noi perspective.\", \"page_offset\": 0},\n",
      "      {\"text\": \"Pentru viitor, una dintre cele mai viabile soluții pentru Uniune ar fi adoptarea și legiferarea unui sistem al suveranității partajate cu statele membre, dar centrat pe cetățenii Europei.\", \"page_offset\": 0},\n",
      "      {\"text\": \"Aceasta nouă concepție ar presupune ca Europa să se îndrepte spre un nou model politic, transnațional, în care depozitul suveranității să fie cetățeanul și nu statul.\", \"page_offset\": 0},\n",
      "      {\"text\": \"Europa, care vreme de secole a difuzat spre alte continente elemente caracteristice din propria ei civilizație, s-a văzut nevoită în ultimii ani să caute noi formule, dintre care prioritară este aceea a integrării, spre a face față unor competitori economici de înaltă performanță: SUA, Japonia și celelalte state dezvoltate din Cercul Pacificului.\", \"page_offset\": 2},\n",
      "      {\"text\": \"Nu renunțarea la ceea ce face „farmecul și prețul sufletului național” ci la „înglobarea lui în întregul culturi europene” și în „orientarea lui spre vestul cărula aparținem [și de care suntem legați pe viață și pe moarte”, după cum aprecia publicistul Eugen Filotti încă din anul 1919, trebuie să fie țelul final al demersului creatorilor români.\", \"page_offset\": 4}\n",
      "    ],\n",
      "    \"explanation\": \"The textbook narrative presents several passages that could influence a student's historical interpretation in a non-neutral way. These include subtle framing choices, value-laden adjectives, and selective emphasis. For example, the text describes the collapse of communism as contributing to the advancement of European political and economic integration, which could be seen as promoting a positive view of European integration. Additionally, the text suggests that a viable solution for the European Union is the adoption of a system of shared sovereignty centered on European citizens, which implies a particular political perspective. The text also frames Europe's historical role as a diffuser of its civilization to other continents, which could be interpreted as Eurocentric. Furthermore, the text discusses the need for Europe to adapt to new competitors, such as the USA and Japan, which could be seen as promoting a particular economic or political agenda. Overall, these passages demonstrate a potential bias in the historical interpretation presented in the textbook.\"\n",
      "  },\n",
      "  {\n",
      "    \"controversy\": \"Use of primary sources\",\n",
      "    \"source_type\": \"PRIMARY_SOURCE_USAGE\",\n",
      "    \"quotes\": [\n",
      "      {\"text\": \"„De-a lungul ultimei jumătăți de secol, India a devenit una dintre cele mai mari economii și o mare putere. Dar poziția Indiei reflectă și cea mai mare realizare a sa: păstrarea aproapeneîntreruptă, a unei conduceri democratice într-o țară săracă, de 1,1 miliarde de oameni. [...] Se pare că toată lumea așteaptă să fie pri- tenul special al Indiei.” George Bush va vizita India la începutul anului [2006]. Administrația lui a afirmat că „nu există o prioritate mai importantă decât extinderea și lărgirea relației noastre cu India”.\", \"page_offset\": 1},\n",
      "      {\"text\": \"„Fac parte din generația cea mai norocoasă pe care a cunoscut-o până acum istoria României. Nici înainte, nici după generația noastră, România n-a mai cunoscut libertatea, belșugul și disponibilitatea de care ne-am bucurat noi, cei care am scris între 1925 și 1940. Generația lui Iorga fusese aproape de-a întregul confiscată de profetismul național și cultural care trebuia să pregătească războiul pentru întregirea neamului. Generația frontului fusese sacrificată să găsim noi o Românie mare, liberă și bogată. Când am început noi să scriem, prin 1925, nici un „ideal național” nu ne solicita imediat. Am fost cei dintâi româ- ni care puteam face și alteca decât istorie națională, filologie românească și profetism cultural fără să avem sentimentul că trădăm cauza neamului”. (Mircea Eliade, Memorii, Editura Humanitas, 1991)\", \"page_offset\": 4}\n",
      "    ],\n",
      "    \"explanation\": \"The textbook includes primary sources that reflect the language, values, or prejudices of their time. For example, a quote from George Bush's administration praising India's economic rise and democratic governance is presented without critical commentary, potentially influencing the reader's perception of India's significance. Another quote from Mircea Eliade's memoirs reflects on the experiences of his generation in Romania, providing a personal perspective on historical events. While these quotes are from historical sources, their selection and presentation could influence the reader's interpretation of historical events.\"\n",
      "  }\n",
      "]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 2 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 2 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in historical interpretation ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in historical interpretation\n",
      "[DEBUG] Quotes count: 5\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=4.0/7, Confidence=0.90, Category=Interpretation & Pedagogy\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.92, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=4.0/7, Confidence=0.80, Category=National or Cultural Centering\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.85, Category=Teleological Narrative\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.88, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Teleological Narrative, Confidence: 0.88\n",
      "\n",
      "--- Issue 2: Use of primary sources ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Use of primary sources\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: PRIMARY_SOURCE_USAGE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.86, Category=Primary Source Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.80, Category=Source Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=,Primary Source Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Primary Source Framing, Confidence: 0.86\n",
      "\n",
      "============================================================\n",
      "BATCH 6: Pages 26-30\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 26 to 30\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 26:\n",
      "[DEBUG]   - Base64 length: 1,347,908 chars\n",
      "[DEBUG] Added page 27:\n",
      "[DEBUG]   - Base64 length: 1,320,992 chars\n",
      "[DEBUG] Added page 28:\n",
      "[DEBUG]   - Base64 length: 1,309,444 chars\n",
      "[DEBUG] Added page 29:\n",
      "[DEBUG]   - Base64 length: 1,274,384 chars\n",
      "[DEBUG] Added page 30:\n",
      "[DEBUG]   - Base64 length: 1,194,852 chars\n",
      "[DEBUG] Average image size: 1,289,516 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 3148 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Value-laden description of historical figures\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"Nicolae Titulescu, care prin gândire și activitate sa practicat a fost un mare adept al ideii de securitate și de colaborare europeană.\", \"page_offset\": 0},\n",
      "        {\"text\": \"Este o inițiativă generoasă, menită să apropie popoarele continentului european de dezideratele și realitățile vremurilor pe care le străbăteam.\", \"page_offset\": 1}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook uses positive adjectives like 'mare adept' and 'inițiativă generoasă' when describing Nicolae Titulescu and his efforts towards European collaboration, which could influence students' interpretation by presenting a biased perspective on his role in history.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Selective emphasis on historical events\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"Deschiderea României spre Europa și spre valorile acesteia este brusc întreruptă o dată cu prăbușirea țării în 1940 în craterul regimurilor totalitare.\", \"page_offset\": 2},\n",
      "        {\"text\": \"România a fost nevoită să se adapteze la realitățile vremurilor, fiind grav compromisă de impunerea brutală a modelelor străine staliniste.\", \"page_offset\": 2}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook emphasizes the negative impact of totalitarian regimes on Romania's integration with Europe, using words like 'brusc întreruptă' and 'impunerea brutală', which could influence students' interpretation by highlighting the disruptions caused by these regimes.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Framing of Romania's historical relationships\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"revenirea României în familia statelor europene\", \"page_offset\": 2},\n",
      "        {\"text\": \"Dezghețul politic care a caracterizat ultima perioadă a regimului lui Gheorghe Gheorghiu-Dej a continuat și în primii ani ai lui Nicolae Ceaușescu.\", \"page_offset\": 3}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook frames Romania's historical relationships with Europe using terms like 'revenirea', suggesting a return to a natural state of belonging, which could influence students' interpretation by implying a historical continuity or natural affiliation with Europe.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Assumptions about cultural identity\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"Marea Unire înfăptuită în 1918 impunea adânci transformări sociale în acord cu aspiratiile societății.\", \"page_offset\": 4},\n",
      "        {\"text\": \"Idei importante de circulație europeană precum ideea națională și ideea democratică ocupă un loc important în gândirea social-politică și filosofică din țara noastră.\", \"page_offset\": 3}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook assumes a connection between Romanian cultural identity and European values, using phrases that link significant historical events and ideas to European integration, which could influence students' interpretation by normalizing the idea of Romania's European identity.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 4 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 4 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Value-laden description of historical figures ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Value-laden description of historical figures\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Language & Framing - Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.92, Category=Moral Loading\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Linguistic Tone\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.85, Category=Moral Loading\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.90, Category=Moral Loading\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.90, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Moral Loading, Confidence: 0.90\n",
      "\n",
      "--- Issue 2: Selective emphasis on historical events ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective emphasis on historical events\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.92, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Linguistic Tone\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.85, Category=Linguistic Tone\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.90, Category=Linguistic Tone\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Linguistic Tone, Confidence: 0.86\n",
      "\n",
      "--- Issue 3: Framing of Romania's historical relationships ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Framing of Romania's historical relationships\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.95, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Linguistic Tone\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.83, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.83\n",
      "\n",
      "--- Issue 4: Assumptions about cultural identity ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Assumptions about cultural identity\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=National or Cultural Centering\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=National or Cultural Centering\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=Teleological Narrative\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=National or Cultural Centering\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.82, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.82\n",
      "\n",
      "============================================================\n",
      "BATCH 7: Pages 31-35\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 31 to 35\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 31:\n",
      "[DEBUG]   - Base64 length: 1,250,092 chars\n",
      "[DEBUG] Added page 32:\n",
      "[DEBUG]   - Base64 length: 1,399,852 chars\n",
      "[DEBUG] Added page 33:\n",
      "[DEBUG]   - Base64 length: 1,455,616 chars\n",
      "[DEBUG] Added page 34:\n",
      "[DEBUG]   - Base64 length: 1,330,212 chars\n",
      "[DEBUG] Added page 35:\n",
      "[DEBUG]   - Base64 length: 1,480,332 chars\n",
      "[DEBUG] Average image size: 1,383,220 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 3218 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\"issues\": [\n",
      "    {\n",
      "        \"controversy\": \"Potential bias in framing Romanian cultural identity\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"În realitate însă numai romanismul poate fi aducător de cultură pentru noi.\", \"page_offset\": 0},\n",
      "            {\"text\": \"Românismul [...] nu se sfieşte a-şi proclama goliciunea, nu şovăie a admite cultura altoită şi a asimila ce i se proptiveşte.\", \"page_offset\": 0},\n",
      "            {\"text\": \"Europenismul vrea să clădească de sus în jos, romanismul se multumeşte a începe cu temelia.\", \"page_offset\": 0}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook presents a potentially biased interpretation of 'românism' (Romanianism) versus 'europenism' (Europeanism), using value-laden language that could influence students' understanding of Romanian cultural identity. The narrative frames 'românism' as potentially superficial and lacking depth compared to 'europenism', which may reflect a particular ideological perspective on cultural development.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Selective emphasis on cultural influences\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"Cultura română, parte componentă a culturii europene.\", \"page_offset\": 1},\n",
      "            {\"text\": \"Filozoful Constantin Rădulescu-Motru susţine în lucrarea Personalismul energetic (1927) că \\\"diferitele culturi naţionale nu sunt decât componentele culturii europene, care este acea care le dă unitatea şi continuitatea\\\".\", \"page_offset\": 1}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook emphasizes the European component of Romanian culture, potentially downplaying other influences. This selective emphasis could shape students' perceptions of Romanian cultural identity and its relationship to European culture.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Framing of Romania's international image\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"O societate şi imaginea pe care indivizii şi grupurile şi-o construiesc despre ea se influenţează reciproc.\", \"page_offset\": 3},\n",
      "            {\"text\": \"România în presa internaţională după 1989. Proiecţii divergente.\", \"page_offset\": 3}\n",
      "        ],\n",
      "        \"explanation\": \"The discussion of Romania's international image post-1989 may reflect a particular perspective on how the country is perceived abroad. The framing of 'divergent projections' could influence students' understanding of Romania's global standing and reputation.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Use of potentially leading questions in exercises\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"Explicaţi la ce se raportează presa internaţională, când analizează evenimentele din România după 1989. Consideraţi că provenienţa ziariştilor dintr-o societate mai avansată economic şi politic decât societatea românească constituie un punct de reper?\", \"page_offset\": 4}\n",
      "        ],\n",
      "        \"explanation\": \"The exercise questions may guide students toward a particular interpretation of how international media perceive Romania, potentially influencing their critical thinking about media representation and cultural bias.\"\n",
      "    }\n",
      "]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 4 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 4 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in framing Romanian cultural identity ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in framing Romanian cultural identity\n",
      "[DEBUG] Quotes count: 3\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=4.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b succeeded on attempt 3\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Primary Source Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.90, Category=Moral Loading\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.70, Category=Primary Source Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.78, Flagged=True\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Narrative Framing, Confidence: 0.78 ⚠️  [FLAGGED FOR REVIEW]\n",
      "\n",
      "--- Issue 2: Selective emphasis on cultural influences ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective emphasis on cultural influences\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Source Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=National or Cultural Centering\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.75, Category=Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.82, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Selection Bias, Confidence: 0.82\n",
      "\n",
      "--- Issue 3: Framing of Romania's international image ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Framing of Romania's international image\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.65, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.84, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Narrative Framing, Confidence: 0.84\n",
      "\n",
      "--- Issue 4: Use of potentially leading questions in exercises ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Use of potentially leading questions in exercises\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Interpretation & Pedagogy\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.92, Category=Perspective Limitation\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 3\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=4.0/7, Confidence=0.80, Category=Interpretation & Pedagogy\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.85, Category=Interpretation & Pedagogy\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=National or Cultural Centering\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Perspective Limitation, Confidence: 0.86\n",
      "\n",
      "============================================================\n",
      "BATCH 8: Pages 36-40\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 36 to 40\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 36:\n",
      "[DEBUG]   - Base64 length: 1,297,504 chars\n",
      "[DEBUG] Added page 37:\n",
      "[DEBUG]   - Base64 length: 1,290,976 chars\n",
      "[DEBUG] Added page 38:\n",
      "[DEBUG]   - Base64 length: 922,992 chars\n",
      "[DEBUG] Added page 39:\n",
      "[DEBUG]   - Base64 length: 1,166,380 chars\n",
      "[DEBUG] Added page 40:\n",
      "[DEBUG]   - Base64 length: 1,284,300 chars\n",
      "[DEBUG] Average image size: 1,192,430 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 3151 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in presenting historical figures\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"Grigore Gafencu este o personalitate marcantă a vieții politice și a diplomației românești interbelice. Ca ministru de externe între anii 1938–1940, în condițiile pericolului generat de expansionismul sovietic, a susținut necesitatea reorientării României către Berlin.\", \"page_offset\": 0},\n",
      "        {\"text\": \"Autor al unui proiect de unificare europeană, și exprimând anumite rezerve în legătură cu capacitatea puterilor europene de a-l înfăptui singur, Gafencu era convins că acesta nu putea deveni realitate decât cu sprijinul SUA.\", \"page_offset\": 0}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook presents Grigore Gafencu in a positive light, highlighting his role in supporting Romania's reorientation towards Berlin during the interwar period and his project for European unification. This selective emphasis could influence students' interpretation of Gafencu's actions and the historical context.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Selective use of primary sources\",\n",
      "      \"source_type\": \"PRIMARY_SOURCE_USAGE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"„Mișcarea Europeană” un proiect de federalizare a statelor europene\", \"page_offset\": 0},\n",
      "        {\"text\": \"„Sunt unți care se miră că ziua de 27 iunie ne-a găsit «singuri». Ei uită că putința de a ne fi unit mai înainte s-a cufundat o lume întreagă. Am fost, deci, singuri fiindcă cei care ne-au putut sprijini nu aveau interes să o facă (orice am fi dus acum sau înainte), și fiindcă cei care ne-au sprijinit îndeodată nu mai erau în viață.”\", \"page_offset\": 1}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook includes quotes from Gafencu's writings and speeches, which could be seen as promoting a particular perspective on European integration and Romania's historical experiences. The selection and presentation of these quotes may influence students' understanding of these topics.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Potential national alignment cues\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"Constituția noastră democratică și parlamentară țară, astfel cum o consfințit-o, în decursul anilor, istoria națională, și înăuntru două mari regi ai trecutului nostru și sfeți-cilor lor să îndelinească minunea înălțării și a unirii neamului nostru.\", \"page_offset\": 1}\n",
      "      ],\n",
      "      \"explanation\": \"The language used in the textbook, such as referring to 'neamului nostru' (our nation), could be seen as promoting a nationalistic perspective. This might influence students' interpretation of historical events and figures in a way that aligns with national sentiments.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Lack of diverse perspectives\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [],\n",
      "      \"explanation\": \"The textbook focuses primarily on Gafencu's contributions and perspectives without presenting a balanced view that includes diverse or opposing viewpoints. This lack of diversity in perspectives could limit students' understanding of the historical context.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 4 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 4 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in presenting historical figures ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in presenting historical figures\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.90, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 failed all 3 attempts — DROPPING from council\n",
      "  ✗ DeepSeek-V3.1 dropped (failed validation after 3 attempts)\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=Moral Loading\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 3\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.85, Category=Omission / Underdevelopment\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 4\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Omission / Underdevelopment, Confidence: 0.86\n",
      "\n",
      "--- Issue 2: Selective use of primary sources ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective use of primary sources\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: PRIMARY_SOURCE_USAGE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Source Handling\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Source Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Source Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.80, Category=Source Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.60, Category=Source Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.82, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Source Selection Bias, Confidence: 0.82\n",
      "\n",
      "--- Issue 3: Potential national alignment cues ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential national alignment cues\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=National or Cultural Centering\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.94, Category=National or Cultural Centering\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=National or Cultural Centering\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.75, Category=National or Cultural Centering\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.85, Category=National or Cultural Centering\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.82, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: National or Cultural Centering, Confidence: 0.82\n",
      "\n",
      "--- Issue 4: Lack of diverse perspectives ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Lack of diverse perspectives\n",
      "[DEBUG] Quotes count: 0\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=4.0/7, Confidence=0.90, Category=Perspective & Representation\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['final{', 'TEXTBOOK_NARRATIVE', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.92, Category=Perspective Limitation\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 3\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=4.0/7, Confidence=0.80, Category=Perspective Limitation\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=Perspective Limitation\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=Perspective Limitation\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.83, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Perspective Limitation, Confidence: 0.83\n",
      "\n",
      "============================================================\n",
      "BATCH 9: Pages 41-45\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 41 to 45\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 41:\n",
      "[DEBUG]   - Base64 length: 1,242,880 chars\n",
      "[DEBUG] Added page 42:\n",
      "[DEBUG]   - Base64 length: 1,185,444 chars\n",
      "[DEBUG] Added page 43:\n",
      "[DEBUG]   - Base64 length: 1,318,068 chars\n",
      "[DEBUG] Added page 44:\n",
      "[DEBUG]   - Base64 length: 1,414,104 chars\n",
      "[DEBUG] Added page 45:\n",
      "[DEBUG]   - Base64 length: 1,290,968 chars\n",
      "[DEBUG] Average image size: 1,290,292 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 4042 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in describing women's emancipation\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Emanciparea femeilor, una dintre marile idei și marile mișcări ale secolului XX, are în prim plan modificarea acestor situații. Femeia, prin pătrunderea sa în spațiul public al muncii, își poate concepe o existență autonomă, descoperind posibilități ale personalității sale ignorate până în acest moment.\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The passage presents women's emancipation in a strongly positive light, potentially influencing interpretation by framing it as an unambiguously beneficial historical development without discussing potential counterarguments or complexities.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Selective emphasis on negative aspects of industrial work\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Munca salariată nu mai este doar o muncă efectuată, pentru alcineva, ci este o sarcină impersonală dirijată de anumite norme formale, supuse unor arbitraje colective și care se desfașoară într-un spațiu despersonalizat, în care drepturile, nu numai patronul.\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The description focuses on the negative aspects of salaried work, potentially creating a biased interpretation by emphasizing its impersonal nature without balancing it with potential benefits.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Framing of historical changes in family and private life\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Familia și-a pierdut funcțiile 'publice' și nu mai are decât funcții 'private'. O parte din sarcinile care ii fusseră încredințate sunt preluate, în mod progresiv, de instanța colectivă.\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The text frames the changes in family functions as a loss, potentially influencing interpretation by suggesting a negative impact on family roles without presenting alternative perspectives.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Use of loaded language in describing social changes\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Către o societate relaxată\",\n",
      "          \"page_offset\": 4\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Viața privată devine un principiu al convingerii sociale\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The use of terms like 'societate relaxată' and framing private life as a 'principiu al convingerii sociale' could be seen as value-laden, potentially influencing interpretation by presenting these changes in a particular light.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in selection of historical personalities\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"James Dean (1931-1955)\\nCariera sa de actor începe în teatru, dar ceea ce îl va face cunoscut este alegerea sa de către regizorul Elia Kazan în rolul Cal Trask din La est de Eden, în urma căruia primește o primă nominalizare la Oscar. Urmează alte două filme care bulversează adolescenții epocii, la numai 24 de ani murind într-un accident de mașină.\",\n",
      "          \"page_offset\": 0\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Simone de Beauvoir (1908-1986)\\nRomancieră și eseistă franceză, a fost una dintre vocile puternice, care în secolul XX a promovat și apărat cu fermitate drepturile femeii. Născută într-o familie de mici gheji, dovedită capacității intelectuale deosebite, ceea ce i-a adus în preajma marilor gânditori francezi contemporani, în primul rând Jean-Paul Sartre.\",\n",
      "          \"page_offset\": 4\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The selection of personalities and the descriptions provided may reflect a particular ideological or cultural bias, potentially influencing interpretation by emphasizing certain figures and their contributions over others.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 5 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 5 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in describing women's emancipation ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in describing women's emancipation\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['final{', 'TEXTBOOK_NARRATIVE', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.93, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Moral Loading\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.85, Category=Perspective Limitation\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Narrative Framing, Confidence: 0.86\n",
      "\n",
      "--- Issue 2: Selective emphasis on negative aspects of industrial work ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective emphasis on negative aspects of industrial work\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.90, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.95, Category=Perspective Limitation\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.85, Category=Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Selection Bias, Confidence: 0.86\n",
      "\n",
      "--- Issue 3: Framing of historical changes in family and private life ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Framing of historical changes in family and private life\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.92, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.87, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.87\n",
      "\n",
      "--- Issue 4: Use of loaded language in describing social changes ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Use of loaded language in describing social changes\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Language & Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.90, Category=Moral Loading\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Moral Loading\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.75, Category=Moral Loading\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.90, Category=Moral Loading\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.85, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Moral Loading, Confidence: 0.85\n",
      "\n",
      "--- Issue 5: Potential bias in selection of historical personalities ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in selection of historical personalities\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.90, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.85, Category=Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.85, Category=Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.70, Category=Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.83, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Selection Bias, Confidence: 0.83\n",
      "\n",
      "============================================================\n",
      "BATCH 10: Pages 46-50\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 46 to 50\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 46:\n",
      "[DEBUG]   - Base64 length: 1,276,160 chars\n",
      "[DEBUG] Added page 47:\n",
      "[DEBUG]   - Base64 length: 1,293,252 chars\n",
      "[DEBUG] Added page 48:\n",
      "[DEBUG]   - Base64 length: 1,340,248 chars\n",
      "[DEBUG] Added page 49:\n",
      "[DEBUG]   - Base64 length: 1,194,012 chars\n",
      "[DEBUG] Added page 50:\n",
      "[DEBUG]   - Base64 length: 1,050,076 chars\n",
      "[DEBUG] Average image size: 1,230,749 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 2990 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in presenting historical events and social changes\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Societate, termen ce vine din latinescul societas, semnifică asociație, sistem organizat de relații între oameni istorice determinate.\",\n",
      "          \"page_offset\": 0\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Secolul XX este, raportat la epoca istorică premergătoare, unul al marilor transformări în ceea ce privește structurile sociale\",\n",
      "          \"page_offset\": 0\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Clasele sociale sunt marcate deosebir de patrimoniu, de venituri, de nivel de educație, de cultură, de mod de viață\",\n",
      "          \"page_offset\": 0\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Omogenizarea nu înseamnă totuși nivelarea, trăsăturile culturale specifice fiecărei țări subzistă, punându-și pecetea asupra societăților respective.\",\n",
      "          \"page_offset\": 1\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Proiectul voluntarist bolșevic urmărește să înfăptuiască treptat, distrugând vechile structuri sociale\",\n",
      "          \"page_offset\": 2\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The textbook presents historical events and social changes with a potential bias towards highlighting significant transformations and impacts on social structures. The language used is generally neutral, but certain phrases and selections of historical sources may subtly influence interpretation.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Use of potentially sensitive historical content\",\n",
      "      \"source_type\": \"PRIMARY_SOURCE_USAGE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"„Un călător al zilelor noastre (…) va recunoaște, dincolo de specificități locale uneori mai sterse, alterori mai marcate, iar satele, în consecință, mai asemănătoare, de la o parte la alta a lumii, chiar dacă locuito-riiii au fost (sau încă sunt) crescuți ortodocși, catolici sau confucianisti - acolo unde dezvoltarea a fost mai adâncă. Există o relație clară între gradul de dezvoltare comunismului și profunzimea acestui regim (...). Folo-sind pretextul modernizării sub zodia comunismului a fost mai profund și a distorsionat mai putenric organizarea socială a societăților mai puțin dezvoltate față de cele mai avansate.”\",\n",
      "          \"page_offset\": 0\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Caricatura de mai jos reprezintă un afiș folosit de propaganda sovietică pentru obținerea susținerii proletariatului și dezvoltarea comunismului, văzute ca necesități ale istoriei, menite să ofere dreptate exploataților, și-a dovedit însă, un lung șir de suferințe și privațiuni, falimentul.\",\n",
      "          \"page_offset\": 2\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The textbook includes historical sources that contain sensitive content related to political ideologies and their impacts. The way these sources are presented and contextualized may influence students' interpretations of historical events and their significance.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 2 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 2 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in presenting historical events and social changes ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in presenting historical events and social changes\n",
      "[DEBUG] Quotes count: 5\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.88, Category=Moral Loading\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=Moral Loading\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.83, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Moral Loading, Confidence: 0.83\n",
      "\n",
      "--- Issue 2: Use of potentially sensitive historical content ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Use of potentially sensitive historical content\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: PRIMARY_SOURCE_USAGE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.78, Category=Moral Loading\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Primary Source Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=Primary Source Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.85, Category=Primary Source Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.82, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Primary Source Framing, Confidence: 0.82\n",
      "\n",
      "============================================================\n",
      "BATCH 11: Pages 51-55\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 51 to 55\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 51:\n",
      "[DEBUG]   - Base64 length: 1,401,804 chars\n",
      "[DEBUG] Added page 52:\n",
      "[DEBUG]   - Base64 length: 1,146,788 chars\n",
      "[DEBUG] Added page 53:\n",
      "[DEBUG]   - Base64 length: 1,118,512 chars\n",
      "[DEBUG] Added page 54:\n",
      "[DEBUG]   - Base64 length: 1,270,764 chars\n",
      "[DEBUG] Added page 55:\n",
      "[DEBUG]   - Base64 length: 1,159,696 chars\n",
      "[DEBUG] Average image size: 1,219,512 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 3601 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\"issues\": [\n",
      "    {\n",
      "        \"controversy\": \"Potential bias in presenting migration causes and effects\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"Migrația contemporană cunoaște numeroase forme de manifestare, pe măsura diversității de cauze care o determină.\", \"page_offset\": 0},\n",
      "            {\"text\": \"Dintre acestea, o importantă de reținut o are migrația economică, determinată de nivelul scăzut de trai și de speranța unei vieți mai bune.\", \"page_offset\": 0},\n",
      "            {\"text\": \"În general, se poate aprecia, mai ales în legătură cu imigrația economică, că aceasta este percepută ca pozitivă atât timp cât țara sau regiunea de imigrație (purtând și de asemena, de migrația dinspre mediul rural spre cel urban) se găsesc într-o perioadă de creștere economică.\", \"page_offset\": 0}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook presents economic migration as being primarily driven by the desire for a better life and economic growth, which could be seen as simplifying complex migration issues. The positive framing of economic migration might influence students' interpretation by emphasizing economic factors over other potential causes or consequences.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Use of potentially sensitive language in primary sources\",\n",
      "        \"source_type\": \"PRIMARY_SOURCE_USAGE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"Mai multe cântece rasiste și xenofobe, ale căror ținte sunt, în mod particular, imigranții români și mai rar, făcuți în provincie Castellon, unde se propagă mai ales pe internet.\", \"page_offset\": 0},\n",
      "            {\"text\": \"Sunt site-uri cu muzică de «bakalo» (termen peiorativ prin care spaniolii desmenează muzica de proastă calitate).\", \"page_offset\": 0}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook includes a primary source that contains xenophobic and racist language directed at Romanian immigrants. While this reflects historical attitudes, its inclusion without critical framing might be seen as normalizing such views.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Presentation of globalization and migration\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"Deplasarea întreprinderilor, favorizată de fenomenul globalizării, provoacă o formă nouă de migrație ce poate fi numită «migrație cadrelor» (specialiști).\", \"page_offset\": 1},\n",
      "            {\"text\": \"Mii de persoane cu înaltă calificare, personal de înalt nivel, directori de firme, specialiști ș.a. Migrează, în contextul unei mobilități legate de dezvoltarea investițiilor pe scară planetară.\", \"page_offset\": 1}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook discusses the impact of globalization on migration patterns, particularly the migration of highly skilled workers. This presentation might influence students by highlighting the global nature of migration and its connection to economic factors.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Framing of economic theories and their impact\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"Neoclasicii sunt numiți astfel «liberali», deoarece susțin libertatea pieței și a schimbului.\", \"page_offset\": 3},\n",
      "            {\"text\": \"Keynesianismul a pus în evidență slăbiciunile teoriei neoclasice.\", \"page_offset\": 4}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook presents different economic theories, such as neoclassicism and Keynesianism, with varying degrees of detail and context. The framing of these theories could influence students' understanding of economic principles and their historical development.\"\n",
      "    }\n",
      "]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 4 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 4 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in presenting migration causes and effects ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in presenting migration causes and effects\n",
      "[DEBUG] Quotes count: 3\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=Omission / Underdevelopment\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.85, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.85\n",
      "\n",
      "--- Issue 2: Use of potentially sensitive language in primary sources ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Use of potentially sensitive language in primary sources\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: PRIMARY_SOURCE_USAGE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=Primary Source Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.70, Category=Primary Source Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Primary Source Framing, Confidence: 0.86\n",
      "\n",
      "--- Issue 3: Presentation of globalization and migration ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Presentation of globalization and migration\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Perspective Limitation\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Perspective Limitation\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.90, Category=Omission / Underdevelopment\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.90, Category=Omission / Underdevelopment\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.84, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Omission / Underdevelopment, Confidence: 0.84\n",
      "\n",
      "--- Issue 4: Framing of economic theories and their impact ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Framing of economic theories and their impact\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b succeeded on attempt 2\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.94, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=True, confidence=True, category=False, reasoning=True\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.70, Category=Asymmetrical Detail\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.84, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Narrative Framing, Confidence: 0.84\n",
      "\n",
      "============================================================\n",
      "BATCH 12: Pages 56-60\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 56 to 60\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 56:\n",
      "[DEBUG]   - Base64 length: 1,294,772 chars\n",
      "[DEBUG] Added page 57:\n",
      "[DEBUG]   - Base64 length: 1,171,152 chars\n",
      "[DEBUG] Added page 58:\n",
      "[DEBUG]   - Base64 length: 1,206,248 chars\n",
      "[DEBUG] Added page 59:\n",
      "[DEBUG]   - Base64 length: 1,343,076 chars\n",
      "[DEBUG] Added page 60:\n",
      "[DEBUG]   - Base64 length: 1,313,912 chars\n",
      "[DEBUG] Average image size: 1,265,832 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 3945 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Presentation of economic theories\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"La începutul anilor '60, mai mulți economiști, conduși de Milton Friedman au reînviat teoria cantitativă a monedei, combătută de analizele keynesiene.\", \"page_offset\": 0},\n",
      "        {\"text\": \"Monetariștii li se datorează și punerea la punct a sistemului flotării libere a valutelor, curs valutar depinzând de evenimentele economice și monetare din fiecară țară și de pe piața mondială, iar nu de un anume etalon.\", \"page_offset\": 0}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook presents Milton Friedman's monetary theory and its impact on currency exchange systems without critically evaluating its implications or controversies, potentially influencing students' interpretation of economic policies.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Historical determinism vs. multiple perspectives\",\n",
      "      \"source_type\": \"PRIMARY_SOURCE_USAGE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"\\\"Ideile filosofilor economiei și politicii, juste sau false, au mai multă importanță decât se crede în general. La drept vorbind, lumea este exclusiv de ele. Oamenii de acțiune, ce se cred complet liberi față de influențele doctrinare, sunt de regulă sclavii vreunui economist din trecut. Vizionarii influenți, care aud voci din cer, distilează utopii născute cu câțiva ani mai devreme în creierul vreunui scriitor de facultate.\\\" (John Maynard Keynes)\", \"page_offset\": 0}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook includes a quote from John Maynard Keynes that suggests historical events are heavily influenced by economic and political philosophies. While this is a primary source, its presentation without additional context or counterpoints may influence students to adopt a deterministic view of history.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Framing of globalisation and economic systems\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"Economia de piață (capitalismul) și socialismul sunt prezentate ca două sisteme economice dominante la nivelul secolului XX.\", \"page_offset\": 1},\n",
      "        {\"text\": \"Mondializarea, un proces nou la scara istoriei, dar s-a intensificat în ultimele decenii.\", \"page_offset\": 1}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook frames globalisation and economic systems in a neutral manner but may influence interpretation by the selection of information and the emphasis on certain aspects over others.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Technological progress and societal impact\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"Progresele înregistrate în domeniul au continuat prin lansarea în anii '70 a stațiilor orbitale, iar în 1981 SUA lansează prima navetă spațială.\", \"page_offset\": 3},\n",
      "        {\"text\": \"Dezvoltarea acestor mijloace de comunicare și de divertisment se va accelera cu rapiditate, importanța lor devenind determinantă pentru omul contemporan.\", \"page_offset\": 4}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook presents technological advancements, particularly in space exploration and communication, in a positive light, highlighting their importance for contemporary society. This framing could influence students' perceptions of technological progress.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Characterization of the 20th century\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"Secolul XX începe sub cele mai bune auspicii, mai mult decât niciodară existând conștiința debutului unei noi epoci: nivelul de viață ameliorat, muncitorii primesc salarii mai bune, timpul de muncă se limitează etc.\", \"page_offset\": 2}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook characterizes the 20th century with both positive and negative aspects, but the initial presentation focuses on positive auspices, potentially influencing students' overall perception of the century.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 5 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 5 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Presentation of economic theories ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Presentation of economic theories\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Perspective & Representation\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.85, Category=Omission / Underdevelopment\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Omission / Underdevelopment\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.80, Category=Omission / Underdevelopment\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 3\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.90, Category=Omission / Underdevelopment\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.83, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Omission / Underdevelopment, Confidence: 0.83\n",
      "\n",
      "--- Issue 2: Historical determinism vs. multiple perspectives ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Historical determinism vs. multiple perspectives\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: PRIMARY_SOURCE_USAGE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Interpretation & Pedagogy\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b succeeded on attempt 2\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.85, Category=Perspective Limitation\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Primary Source Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.85, Category=Source Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.82, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Primary Source Framing, Confidence: 0.82\n",
      "\n",
      "--- Issue 3: Framing of globalisation and economic systems ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Framing of globalisation and economic systems\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.93, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=1/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=Asymmetrical Detail\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.78, Flagged=True\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Omission / Underdevelopment, Confidence: 0.78 ⚠️  [FLAGGED FOR REVIEW]\n",
      "\n",
      "--- Issue 4: Technological progress and societal impact ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Technological progress and societal impact\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.96, Category=Teleological Narrative\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Teleological Narrative\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=True, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking failed all 3 attempts — DROPPING from council\n",
      "  ✗ Kimi-K2-Thinking dropped (failed validation after 3 attempts)\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 4\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.83, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Teleological Narrative, Confidence: 0.83\n",
      "\n",
      "--- Issue 5: Characterization of the 20th century ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Characterization of the 20th century\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.95, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.85, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Narrative Framing, Confidence: 0.85\n",
      "\n",
      "============================================================\n",
      "BATCH 13: Pages 61-65\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 61 to 65\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 61:\n",
      "[DEBUG]   - Base64 length: 1,229,668 chars\n",
      "[DEBUG] Added page 62:\n",
      "[DEBUG]   - Base64 length: 1,166,964 chars\n",
      "[DEBUG] Added page 63:\n",
      "[DEBUG]   - Base64 length: 1,248,640 chars\n",
      "[DEBUG] Added page 64:\n",
      "[DEBUG]   - Base64 length: 1,273,768 chars\n",
      "[DEBUG] Added page 65:\n",
      "[DEBUG]   - Base64 length: 1,160,768 chars\n",
      "[DEBUG] Average image size: 1,215,961 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 4260 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in the presentation of environmental issues\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"În secolul XX viaţa de zi cu zi a omenirii s-a schimbat profund, fiecare dintre noi dispunând de un nivel de trai incomparabil cu cel din oricare altă epocă. Noul mod de viaţă, bazat pe maşini, pe energie electrică etc. Distruge însă treptat mediul înconjurător.\",\n",
      "          \"page_offset\": 0\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Pentru toată lumea, masele plastice reprezintă unul dintre cele mai comune materiale. Că plastul este ieftin şi rezistent, masele plastice sunt pretutindeni, inclusiv în natură, chiar dacă plasticul nu se descompune şi astfel nu se elimină pe cale naturală.\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The passage highlights the negative environmental impact of modern life and plastic use without presenting a balanced view of the issue. The language used is critical of modern advancements and their environmental consequences, potentially influencing the student's interpretation of historical and contemporary environmental issues.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in the presentation of historical events and their impact\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Secolul XX a reprezentat pentru România o evoluţie rapidă de la o economie predominant agrară şi rurală spre o economie în primul rând industrială şi urbană, ritmul abrupt de evoluţie, în perioada comunistă, determinând numeroase disfuncţionalităţi şi destructurări ale cărora consecinţe sunt încă prezente.\",\n",
      "          \"page_offset\": 2\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The passage presents a negative view of the communist period in Romania, focusing on its negative consequences. This could influence the student's interpretation of this historical period by emphasizing its failures without providing a balanced view.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in the presentation of diaspora and exile\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Diaspora românească are o îndelungată tradiţie, cauzele sale fiind multiple (condiţiile formării poporului român, evoluţiile istorice, represiunile politice, neajunsurile economice etc.). Faptul că această diasporă să joace un rol deosebit în evoluţiile contemporane, se pot sublinia modificările de structură înregistrate în perioada postbelică, instalarea comunismului şi represiunile pe care acesta le-a pus în practică determinând foarte mulţi intelectuali şi oameni politici să aleagă calea exilului şi să îngroaşe rândurile românilor care trăiesc în afară ţării (este vorba, în primul rând de comunităţile din America de Nord şi Europa occidentală).\",\n",
      "          \"page_offset\": 4\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The passage presents a sympathetic view of the Romanian diaspora, emphasizing the political and economic reasons for their displacement. This could influence the student's interpretation by framing the diaspora in a predominantly positive or sympathetic light.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Selective emphasis on certain historical figures\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Virgil Madgearu (1887 -1940) s-a născut la Galaţi, unde şi-a realizat studiile primare şi liceale; a absolvit studiile economice la Leipzig, unde a obţinut şi titlul de doctor, în 1911. [...] În 28 noiembrie 1940 Virgil Madgearu a fost asasinat.\",\n",
      "          \"page_offset\": 2\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Paul Goma s-a născut la 2 octombrie 1935. [...] În 1967 romanul său Ostinato este trimis în Occident, în 1971 apărând în traducere germană. În toamna lui 1977, la presiunea Securităţii, pleacă în exil la Paris, unde va continua lupta anticomunistă.\",\n",
      "          \"page_offset\": 4\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The textbook highlights certain historical figures who were critical of or suffered under communist regimes. The selection and presentation of these figures could influence the student's interpretation by emphasizing anti-communist perspectives.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 4 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 4 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in the presentation of environmental issues ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in the presentation of environmental issues\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Language & Framing - Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.88, Category=Linguistic Tone\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Linguistic Tone\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.95, Category=Moral Loading\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Linguistic Tone\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.86\n",
      "\n",
      "--- Issue 2: Potential bias in the presentation of historical events and their impact ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in the presentation of historical events and their impact\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Language & Framing - Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b succeeded on attempt 2\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 3\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.87, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.87\n",
      "\n",
      "--- Issue 3: Potential bias in the presentation of diaspora and exile ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in the presentation of diaspora and exile\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b succeeded on attempt 2\n",
      "[DEBUG] gpt-oss-120b returned keys: ['final{', 'TEXTBOOK_NARRATIVE', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.92, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.90, Category=Group Representation\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.84, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.84\n",
      "\n",
      "--- Issue 4: Selective emphasis on certain historical figures ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective emphasis on certain historical figures\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.90, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.85, Category=Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.80, Category=Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.84, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Selection Bias, Confidence: 0.84\n",
      "\n",
      "============================================================\n",
      "BATCH 14: Pages 66-70\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 66 to 70\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 66:\n",
      "[DEBUG]   - Base64 length: 1,191,132 chars\n",
      "[DEBUG] Added page 67:\n",
      "[DEBUG]   - Base64 length: 1,248,124 chars\n",
      "[DEBUG] Added page 68:\n",
      "[DEBUG]   - Base64 length: 1,013,116 chars\n",
      "[DEBUG] Added page 69:\n",
      "[DEBUG]   - Base64 length: 1,305,632 chars\n",
      "[DEBUG] Added page 70:\n",
      "[DEBUG]   - Base64 length: 1,173,224 chars\n",
      "[DEBUG] Average image size: 1,186,245 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 4066 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in presenting the impact of communist regime on Romanian science\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Instalarea regimului comunist, în pofida unei evoluții pozitive, va provoca numeroase dificultăți cercetării românești, în primul rând imposibilitatea de a colabora cu oameni de știință occidentali, dar și lipsa resurselor necesare desfășurării activității, subfinanțarea accentuându-se după 1990.\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The passage could influence interpretation by suggesting that the communist regime had a uniformly negative impact on Romanian science, which might be seen as a biased perspective. The text implies a causal link between the communist regime and the difficulties faced by Romanian science without presenting a balanced view of the period.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Selective emphasis on the negative aspects of the communist regime's impact on science\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Declinul cercetării românești. Perioada celui de-al doilea război mondial, iar după aceea instalarea comunismului a determinat un regres în cercetarea științifică românească, mulți dintre oamenii de știință români refugiindu-se în Occident.\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"This passage emphasizes the negative impact of the communist regime on Romanian scientific research by highlighting the decline and the emigration of scientists. While this is a valid historical point, the presentation might be seen as selective if it doesn't also discuss any potential positive developments or complexities during that period.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in the selection of historical figures\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Nicolae Constantin Paulescu (1869-1931)... Premiul Nobel pentru Fiziologie și Medicină va fi acordat cercetătorilor canadieni.\",\n",
      "          \"page_offset\": 0\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"George Emil Palade... În 1961 este ales membru al National Academy of Science, iar în 1974 primește Premiul Nobel pentru Fiziologie și Medicină.\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The textbook highlights Romanian scientists who achieved international recognition, such as Nicolae Constantin Paulescu and George Emil Palade. While this is informative, the selection might be seen as biased if it disproportionately focuses on figures who were successful abroad, potentially overlooking contributions of scientists who remained in Romania or faced different challenges.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Framing of the 'brain drain' phenomenon\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Un fenomen și mai grav este o anumită 'migrație a creierelor', respectiv plecarea, în primul rând, a tinerilor cu un potențial ridicat pentru a se integra unor colective de cercetare străine.\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The description of the 'brain drain' as a 'phenomenon and more serious' could influence students' interpretation by framing it as inherently negative without providing a balanced discussion of its causes or potential benefits.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Use of a potentially loaded term\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"„Numai alianța provizorie destul de bizară dintre capitalismul liberal și comunism, unite în lupta împotriva unui adversar comun, fascismul, a salvat democrațiile.\",\n",
      "          \"page_offset\": 3\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The use of the term 'bizară' (bizarre) to describe the alliance between liberal capitalism and communism against fascism could be seen as value-laden, potentially influencing the reader's perception of this historical alliance.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 5 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 5 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in presenting the impact of communist regime on Romanian science ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in presenting the impact of communist regime on Romanian science\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 3\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=4.0/7, Confidence=0.80, Category=Perspective Limitation\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.85, Category=Perspective Limitation\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.85, Category=Omission / Underdevelopment\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Perspective Limitation, Confidence: 0.86\n",
      "\n",
      "--- Issue 2: Selective emphasis on the negative aspects of the communist regime's impact on science ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective emphasis on the negative aspects of the communist regime's impact on science\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.85, Category=Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Omission / Underdevelopment\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Selection Bias, Confidence: 0.86\n",
      "\n",
      "--- Issue 3: Potential bias in the selection of historical figures ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in the selection of historical figures\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Selection Bias\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.86, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.85, Category=Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.75, Category=Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.84, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Selection Bias, Confidence: 0.84\n",
      "\n",
      "--- Issue 4: Framing of the 'brain drain' phenomenon ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Framing of the 'brain drain' phenomenon\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['final{', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.92, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.80, Category=Linguistic Tone\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=True, category=False, reasoning=True\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 3\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.86\n",
      "\n",
      "--- Issue 5: Use of a potentially loaded term ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Use of a potentially loaded term\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Language & Framing, Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=True, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b succeeded on attempt 2\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.92, Category=Linguistic Tone\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Linguistic Tone\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.85, Category=Linguistic Tone\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 3\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Linguistic Tone\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Linguistic Tone, Confidence: 0.86\n",
      "\n",
      "============================================================\n",
      "BATCH 15: Pages 71-75\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 71 to 75\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 71:\n",
      "[DEBUG]   - Base64 length: 1,396,228 chars\n",
      "[DEBUG] Added page 72:\n",
      "[DEBUG]   - Base64 length: 1,228,332 chars\n",
      "[DEBUG] Added page 73:\n",
      "[DEBUG]   - Base64 length: 1,123,148 chars\n",
      "[DEBUG] Added page 74:\n",
      "[DEBUG]   - Base64 length: 1,215,052 chars\n",
      "[DEBUG] Added page 75:\n",
      "[DEBUG]   - Base64 length: 1,027,568 chars\n",
      "[DEBUG] Average image size: 1,198,065 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 2516 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in describing the geographical spread of liberal democracy\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"O mare parte a lumii se află în afara democrației liberale. Era și cazul unor mari zone ale Africii și Asiei care au fost supuse colonizării europene.\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The passage implies that liberal democracy is primarily associated with European and Western countries, potentially marginalizing non-Western democratic experiences.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Selective emphasis on the role of external factors in shaping Japanese democracy\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Japonia a fost ocupată de armata americană. O vastă epurare a urmat în țară, care sub presiunea ocupantului american trebuia să înțeleagă reforme profunde.\",\n",
      "          \"page_offset\": 3\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The text focuses on the American occupation's role in Japan's democratization, potentially downplaying internal factors or Japanese agency in the process.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Value-laden description of the British parliamentary model\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Modelul politic parlamentar s-a încadrat în cerințele democrației liberale, reușind să se mențină fără întrerupere în Marea Britanie, chiar și în perioadele când în alte state cu tradiție democratică s-au afirmat regimuri autoritare sau totalitare.\",\n",
      "          \"page_offset\": 2\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The passage presents the British parliamentary model as a successful and enduring example of liberal democracy, potentially implying its superiority over other models.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in the selection of historical sources\",\n",
      "      \"source_type\": \"PRIMARY_SOURCE_USAGE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"„Secolul nostru [sec. XX] demonstrează că victoria idealurilor de justiție și egalitate este întotdeauna efemeră, dar și faptul că, dacă reușim să ne păstrăm libertatea, putem relua totul de la capăt…” (Leo Valiani)\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The inclusion of Leo Valiani's quote may reflect the textbook's emphasis on certain political ideologies or perspectives, potentially influencing students' interpretations.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 4 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 4 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in describing the geographical spread of liberal democracy ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in describing the geographical spread of liberal democracy\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=National or Cultural Centering\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.92, Category=Group Representation\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=4.0/7, Confidence=0.80, Category=Perspective Limitation\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.90, Category=Group Representation\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.85, Category=National or Cultural Centering\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.83, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: National or Cultural Centering, Confidence: 0.83\n",
      "\n",
      "--- Issue 2: Selective emphasis on the role of external factors in shaping Japanese democracy ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective emphasis on the role of external factors in shaping Japanese democracy\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b succeeded on attempt 2\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.90, Category=Agency Attribution\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=4.0/7, Confidence=0.80, Category=Agency Attribution\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.85, Category=Agency Attribution\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.90, Category=Agency Attribution\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Agency Attribution, Confidence: 0.86\n",
      "\n",
      "--- Issue 3: Value-laden description of the British parliamentary model ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Value-laden description of the British parliamentary model\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Language & Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Moral Loading\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=National or Cultural Centering\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.80, Category=Teleological Narrative\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 3\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.82, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.82\n",
      "\n",
      "--- Issue 4: Potential bias in the selection of historical sources ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in the selection of historical sources\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: PRIMARY_SOURCE_USAGE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Source Selection Bias\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Source Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Source Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.80, Category=Source Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=True, reasoning=True\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 3\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.65, Category=Source Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.80, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Source Selection Bias, Confidence: 0.80\n",
      "\n",
      "============================================================\n",
      "BATCH 16: Pages 76-80\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 76 to 80\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 76:\n",
      "[DEBUG]   - Base64 length: 1,221,972 chars\n",
      "[DEBUG] Added page 77:\n",
      "[DEBUG]   - Base64 length: 1,123,708 chars\n",
      "[DEBUG] Added page 78:\n",
      "[DEBUG]   - Base64 length: 1,345,800 chars\n",
      "[DEBUG] Added page 79:\n",
      "[DEBUG]   - Base64 length: 1,171,756 chars\n",
      "[DEBUG] Added page 80:\n",
      "[DEBUG]   - Base64 length: 1,153,472 chars\n",
      "[DEBUG] Average image size: 1,203,341 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 3081 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in presenting historical events\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Statele Unite reprezintă o democrație în care votul universal este sursa puterii executive și legislative.\",\n",
      "          \"page_offset\": 0\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"După 1945, Statele Unite au devenit apărătoare și promotore ale democrației occidentale, bazată pe principii: libertății, pluralismului politic, a suveranității naționale, a separației puterilor în stat și a respectării drepturilor omului.\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The textbook presents the United States as a promoter of democracy and protector of human rights after 1945, which could be seen as promoting a particular political perspective. The language used is neutral but the selection of information might be seen as emphasizing a positive view of the U.S. role in global politics.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Use of primary sources and their interpretation\",\n",
      "      \"source_type\": \"PRIMARY_SOURCE_USAGE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"\\\"În acest moment al istoriei fiecare națiune trebuie să aleagă între două drumuri ... Unul are la bază dorința, și se remarcă prin instituțiile guvern reprezentativ, alegerile libere, garanția respectării libertății personale, de exprimare și religie.\\\"\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The primary source from Truman's doctrine is used to illustrate the ideological divide during the Cold War. The way it is presented and contextualized could influence the interpretation of the U.S. role in promoting democracy and freedom.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Framing of political systems\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Regimul politic instaurat de Republica a V-a, nu a suferit modificări majore în timpul guvernării socialiștilor sau a grupărilor de dreapta care i-au urmat.\",\n",
      "          \"page_offset\": 2\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The description of the French Fifth Republic's political system as stable and enduring across different political groups could be seen as presenting a particular interpretation of political stability and the effectiveness of the system.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Selective emphasis on certain historical aspects\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"În statele cu tradiție autoritară în care revoluția industrială a favorizat dezvoltarea socială, a sporit considerabil rolul Parlamentului, care a contestat în primii ani ai secolului XX autoritatea absolută a suveranilor.\",\n",
      "          \"page_offset\": 4\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The focus on the role of industrial revolution in changing political structures in authoritarian states might be seen as selectively emphasizing certain factors over others, potentially influencing the interpretation of historical developments.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 4 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 4 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in presenting historical events ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in presenting historical events\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Perspective Limitation\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.85, Category=Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Selection Bias, Confidence: 0.86\n",
      "\n",
      "--- Issue 2: Use of primary sources and their interpretation ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Use of primary sources and their interpretation\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: PRIMARY_SOURCE_USAGE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Primary Source Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.85, Category=Primary Source Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.70, Category=Source Handling: Primary Source Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Primary Source Framing, Confidence: 0.86\n",
      "\n",
      "--- Issue 3: Framing of political systems ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Framing of political systems\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Interpretation & Pedagogy\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b succeeded on attempt 2\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.86\n",
      "\n",
      "--- Issue 4: Selective emphasis on certain historical aspects ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective emphasis on certain historical aspects\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=Omission / Underdevelopment\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=True, confidence=True, category=False, reasoning=True\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.75, Category=Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Selection Bias, Confidence: 0.86\n",
      "\n",
      "============================================================\n",
      "BATCH 17: Pages 81-85\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 81 to 85\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 81:\n",
      "[DEBUG]   - Base64 length: 1,181,368 chars\n",
      "[DEBUG] Added page 82:\n",
      "[DEBUG]   - Base64 length: 1,179,612 chars\n",
      "[DEBUG] Added page 83:\n",
      "[DEBUG]   - Base64 length: 1,167,996 chars\n",
      "[DEBUG] Added page 84:\n",
      "[DEBUG]   - Base64 length: 1,322,868 chars\n",
      "[DEBUG] Added page 85:\n",
      "[DEBUG]   - Base64 length: 1,138,436 chars\n",
      "[DEBUG] Average image size: 1,198,056 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 2315 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Framing of liberal democracy\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Democrația liberală nu a fost bine adaptată evoluției sociale a marilor țări industriale.\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The statement implies that liberal democracy was inherently flawed or inadequate for industrialized countries, potentially influencing students to view it negatively.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Description of totalitarian regimes\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Totalitarismul = regim care aplică sau preconizează dictatura unei minorități, majoritatea populației fiind lipsită de drepturi și libertăți.\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The definition is neutral and factual, providing a clear understanding of totalitarianism.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Framing of fascist and communist ideologies\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Fascismul și comunismul sunt două fațade ale aceluiași fenomen, totalitarismul.\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The comparison of fascism and communism as two sides of the same totalitarian phenomenon could be seen as influencing interpretation by equating the two ideologies.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Use of primary sources\",\n",
      "      \"source_type\": \"PRIMARY_SOURCE_USAGE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"„O bună parte din ceea ce este comunismul trebuie găsit în ceea ce au făcut comuniștii.”\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The quote from Peter Lee provides a reflective perspective on communism, encouraging critical thinking about the ideology.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Description of Stalin's regime\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Partidul Comunist al Uniunii Sovietice rămânea principalul agent al centralizării.\",\n",
      "          \"page_offset\": 3\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The statement is factual, describing the role of the Communist Party in the Soviet Union under Stalin's rule.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 5 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 5 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Framing of liberal democracy ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Framing of liberal democracy\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.88, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=4.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.84, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Narrative Framing, Confidence: 0.84\n",
      "\n",
      "--- Issue 2: Description of totalitarian regimes ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Description of totalitarian regimes\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=2.0/7, Confidence=0.90, Category=Language & Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=1/7, Confidence=0.97, Category=Linguistic Tone\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Moral Loading\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=1/7, Confidence=0.90, Category=Language & Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=True, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 3\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.90, Category=: Omission / Underdevelopment\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.90, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Moral Loading, Confidence: 0.90\n",
      "\n",
      "--- Issue 3: Framing of fascist and communist ideologies ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Framing of fascist and communist ideologies\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=True, category=False, reasoning=True\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b succeeded on attempt 3\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.78, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=4.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.82, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Narrative Framing, Confidence: 0.82\n",
      "\n",
      "--- Issue 4: Use of primary sources ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Use of primary sources\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: PRIMARY_SOURCE_USAGE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.88, Category=Primary Source Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=1/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=1/7, Confidence=0.90, Category=Source Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=True, category=True, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 3\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.70, Category=Primary Source Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Primary Source Framing, Confidence: 0.86\n",
      "\n",
      "--- Issue 5: Description of Stalin's regime ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Description of Stalin's regime\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=1/7, Confidence=0.96, Category=Agency Attribution\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Omission / Underdevelopment\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.85, Category=Omission / Underdevelopment\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.80, Category=Omission / Underdevelopment\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.78, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Omission / Underdevelopment, Confidence: 0.78\n",
      "\n",
      "============================================================\n",
      "BATCH 18: Pages 86-90\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 86 to 90\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 86:\n",
      "[DEBUG]   - Base64 length: 1,286,736 chars\n",
      "[DEBUG] Added page 87:\n",
      "[DEBUG]   - Base64 length: 1,343,120 chars\n",
      "[DEBUG] Added page 88:\n",
      "[DEBUG]   - Base64 length: 1,125,496 chars\n",
      "[DEBUG] Added page 89:\n",
      "[DEBUG]   - Base64 length: 1,342,964 chars\n",
      "[DEBUG] Added page 90:\n",
      "[DEBUG]   - Base64 length: 1,174,496 chars\n",
      "[DEBUG] Average image size: 1,254,562 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 4636 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\"issues\": [\n",
      "    {\n",
      "        \"controversy\": \"Potential bias in describing communist regimes\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"Democra\\u00e7ie popular\\u0103 = denumire ini\\u021bial\\u0103 dat\\u0103 regimurilor comuniste instaurate \\u00een statele din Europa \\u00eentre 1945-1948, \\u00een care puterea era exercit\\u0103t\\u0103 de c\\u0103tre Partidul Comunist.\", \"page_offset\": 0},\n",
      "            {\"text\": \"Regimurile de \\u201edemocra\\u021bie popular\\u0103\\u201f s-au men\\u021finut \\u00een majoritate statelor unde aceast\\u0103 func\\u021bionau cu sprijinul Armatei Ro\\u021fii.\", \"page_offset\": 1}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook defines 'democra\\u021bie popular\\u0103' (people's democracy) as an initial name for communist regimes, establishing a direct link between the two concepts. This framing could influence students' interpretation by normalizing the connection between communist regimes and the term 'democracy', potentially downplaying the authoritarian nature of these regimes.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Selective emphasis on negative aspects of communist regimes\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"colectivizarea \\u00eapm\\u00e2nturilor, na\\u021bionalizarea \\u00eentreprinderilor \\u021fi planificarea marcheaz\\u0103 trecerea la o economie de tip comunist.\", \"page_offset\": 0},\n",
      "            {\"text\": \"instaurarea unui totalitarism de tip stalinist.\", \"page_offset\": 0}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook emphasizes negative aspects such as collectivization and totalitarianism when describing the implementation of communist regimes in Eastern Europe. This selective emphasis could influence students by creating a predominantly negative perception of communist economic and political systems.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Lack of critical perspective on primary sources\",\n",
      "        \"source_type\": \"PRIMARY_SOURCE_USAGE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"\\u201eLa sf\\u00e2r\\u021fitul anilor \\u201840, majoritatea statelor est-europene devenise dependente de Uniunea Sovietic\\u0103, fiind conduse de dictatori stalinisti.\\u201f\", \"page_offset\": 1},\n",
      "            {\"text\": \"\\u201eSuntem hot\\u0103r\\u00e2\\u021fi s\\u0103 lichid\\u0103m cu des\\u0103v\\u00e2r\\u021fire toate ideile \\u00eenvechecite, toat\\u0103 cultura \\u00eenvechecit\\u0103, obiceiuile \\u00eenvechecite din care clasele exploatatoare au otr\\u0103vit con\\u021ftiinta poporului timp de milenii.\\u201f\", \"page_offset\": 2}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook includes primary sources that contain strong language against previous ideologies and cultures. While these sources reflect historical attitudes, their inclusion without critical commentary might influence students by presenting these extreme views as representative of the periods discussed.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Potential bias in presenting historical figures\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"Tito, pre\\u021fedinte al Iugoslaviei, liderul Partidului Comunist Iugoslav de la crearea sa.\", \"page_offset\": 1},\n",
      "            {\"text\": \"Mao Zedong (1893-1976)\\nPrincipalul artizan al luptei \\u00econtra Japoniei \\u00eentre 1937-1945, el a condus victorios comunismul \\u00een r\\u0103zboiul civil, instaur\\u00e2nd \\u00een octombrie 1949 Republica Popular\\u0103 Chinez\\u0103.\", \"page_offset\": 3}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook presents historical figures like Tito and Mao Zedong in a primarily positive light, focusing on their roles in establishing communist regimes. This portrayal could influence students by emphasizing their achievements without equally presenting their controversial actions or the negative consequences of their policies.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Simplified portrayal of complex historical events\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"Mi\\u021fcarea fascist\\u0103 a fost fondat\\u0103 \\u00een martie 1919 de fostul socialist Benito Mussolini.\", \"page_offset\": 4},\n",
      "            {\"text\": \"Ea nu reprezenta ini\\u021bial dec\\u00e2t o mic\\u0103 forma\\u021fiune extremist\\u0103, f\\u0103r\\u0103 influen\\u021b\\u0103 real\\u0103 \\u00een via\\u021fa politic\\u0103.\", \"page_offset\": 4}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook simplifies the origins of fascist movements by describing them as initially small and without real influence. This simplification could influence students by not fully conveying the complexity and initial support or the rapid rise of such movements.\"\n",
      "    }\n",
      "]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 5 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 5 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in describing communist regimes ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in describing communist regimes\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.88, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Linguistic Tone\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=Linguistic Tone\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.83, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.83\n",
      "\n",
      "--- Issue 2: Selective emphasis on negative aspects of communist regimes ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective emphasis on negative aspects of communist regimes\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=4.0/7, Confidence=0.90, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b succeeded on attempt 2\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.85, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.85, Category=Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.78, Flagged=True\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Selection Bias, Confidence: 0.78 ⚠️  [FLAGGED FOR REVIEW]\n",
      "\n",
      "--- Issue 3: Lack of critical perspective on primary sources ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Lack of critical perspective on primary sources\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: PRIMARY_SOURCE_USAGE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.94, Category=Primary Source Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=True, reasoning=True\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 3\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=Primary Source Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.91, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Primary Source Framing, Confidence: 0.91\n",
      "\n",
      "--- Issue 4: Potential bias in presenting historical figures ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in presenting historical figures\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Language & Framing - Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.90, Category=Omission / Underdevelopment\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=4.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.85, Category=Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.85, Category=Omission / Underdevelopment\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Omission / Underdevelopment, Confidence: 0.86\n",
      "\n",
      "--- Issue 5: Simplified portrayal of complex historical events ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Simplified portrayal of complex historical events\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Omission / Underdevelopment\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b succeeded on attempt 2\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Omission / Underdevelopment\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Omission / Underdevelopment\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.80, Category=Omission / Underdevelopment\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=Omission / Underdevelopment\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Omission / Underdevelopment, Confidence: 0.86\n",
      "\n",
      "============================================================\n",
      "BATCH 19: Pages 91-95\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 91 to 95\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 91:\n",
      "[DEBUG]   - Base64 length: 1,270,492 chars\n",
      "[DEBUG] Added page 92:\n",
      "[DEBUG]   - Base64 length: 1,311,264 chars\n",
      "[DEBUG] Added page 93:\n",
      "[DEBUG]   - Base64 length: 1,345,016 chars\n",
      "[DEBUG] Added page 94:\n",
      "[DEBUG]   - Base64 length: 1,303,856 chars\n",
      "[DEBUG] Added page 95:\n",
      "[DEBUG]   - Base64 length: 1,183,524 chars\n",
      "[DEBUG] Average image size: 1,282,830 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 3749 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in presenting fascist ideology\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Fascismul „reprezintă o dictatură cu mijloace teroriste a celor mai reacţionare, şovine şi imperialiste elemente ale capitalului financiar.”\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The textbook uses a quote from Gheorghi Dimitrov that presents fascism in a strongly negative light, characterizing it as a 'dictatorship with terrorist means of the most reactionary, chauvinist, and imperialist elements of finance capital.' This framing could influence students' interpretation by presenting a biased view of fascism without providing a balanced perspective.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Selective presentation of historical sources\",\n",
      "      \"source_type\": \"PRIMARY_SOURCE_USAGE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"„Noi cerem unirea tuturor germanilor într-o Germanie Mare, conform cu dreptul popoarelor de a dispune de ei înşişi.”\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The textbook includes a primary source from the Nazi Party's program, which demands the unification of all Germans. While this is a historical fact, the selection of this particular quote without additional context or counterpoints might influence students' understanding of Nazi ideology by focusing on its nationalist aspects without fully representing its broader implications or criticisms.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in presenting Nazi ideology\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Naziștii și-au arogat dreptul de a controla justiția.\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The textbook states that 'Nazis arrogated to themselves the right to control justice,' which is a factual statement about the Nazi regime's actions. However, the way it is presented could be seen as influencing interpretation by highlighting the authoritarian nature of the Nazi regime without providing a balanced view of its legal and political structures.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Framing of historical events\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Înfrângerea din 1918 a Germaniei, prăbușirea Reichului imperial, războiul civil, umilirea primei puteri industriale a Europei de către tratatul de la Versailles, declanșarea unei inflații fără precedent au favorizat ascensiunea grupărilor de dreapta.\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The textbook describes the aftermath of World War I in Germany, highlighting factors that contributed to the rise of right-wing groups. The framing of these events could influence students' interpretation by emphasizing the negative consequences of the Treaty of Versailles and the economic crisis, potentially creating a sympathetic view of the circumstances leading to the rise of Nazism.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Presentation of political debates\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Parlamentul a reprezentat una dintre instituțiile fundamentale ale României în epoca modernă și contemporană.\",\n",
      "          \"page_offset\": 3\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The textbook discusses the role of the Romanian Parliament in the early 20th century, presenting it as a fundamental institution. This presentation could influence students' interpretation by emphasizing the importance of parliamentary debates and political processes in modern Romania, potentially shaping their views on democratic governance.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 5 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 5 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in presenting fascist ideology ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in presenting fascist ideology\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Primary Source Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Primary Source Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 3\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Primary Source Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.80, Category=Primary Source Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.84, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Primary Source Framing, Confidence: 0.84\n",
      "\n",
      "--- Issue 2: Selective presentation of historical sources ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective presentation of historical sources\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: PRIMARY_SOURCE_USAGE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=4.0/7, Confidence=0.90, Category=Source Handling\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.93, Category=Source Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Source Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.70, Category=Source Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.85, Category=Source Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.78, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Primary Source Framing, Confidence: 0.78\n",
      "\n",
      "--- Issue 3: Potential bias in presenting Nazi ideology ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in presenting Nazi ideology\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.92, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Linguistic Tone\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.90, Category=Language & Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Linguistic Tone, Confidence: 0.86\n",
      "\n",
      "--- Issue 4: Framing of historical events ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Framing of historical events\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['final{', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.86\n",
      "\n",
      "--- Issue 5: Presentation of political debates ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Presentation of political debates\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Language & Framing - Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=1/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.75, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.78, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Narrative Framing, Confidence: 0.78\n",
      "\n",
      "============================================================\n",
      "BATCH 20: Pages 96-100\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 96 to 100\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 96:\n",
      "[DEBUG]   - Base64 length: 1,252,568 chars\n",
      "[DEBUG] Added page 97:\n",
      "[DEBUG]   - Base64 length: 1,281,232 chars\n",
      "[DEBUG] Added page 98:\n",
      "[DEBUG]   - Base64 length: 1,269,768 chars\n",
      "[DEBUG] Added page 99:\n",
      "[DEBUG]   - Base64 length: 1,276,444 chars\n",
      "[DEBUG] Added page 100:\n",
      "[DEBUG]   - Base64 length: 1,106,508 chars\n",
      "[DEBUG] Average image size: 1,237,304 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 3647 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in the presentation of historical political figures and events\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Dinamica partidelor politice Partidul Național Liberal a continuat a juca un important rol politic, reprezentând în practica cel mai puternic partid al perioadei interbelice.\",\n",
      "          \"page_offset\": 0\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Sub influența puternicelor personalități care fuseseră România Mare, în primul rând a lui I.I.C. Brătianu, precum și datoriile prezentate pe tron a regelui Ferdinand, viața politică a regatului s-a dezvoltat firesc, pe un fond de stabilitate, până spre sfârșitul anilor 1920, preocupată de refacerea și unificarea țării abia alcătuite, de stabilirea căilor (I.I.C.Brătianu, V. Brătianu, I.G.Duca) și moartea regelui Ferdinand a creat un gol de putere de care a profitat atât Carol al II-lea cât și Garda de Fier.\",\n",
      "          \"page_offset\": 1\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Dictatura proletariatului, monopolul puterii deținut de către un partid unic îngrădește drepturile cetățenești. Lichidarea oricărei opoziții, prin forță și teroare, a fost o caracteristică a regimurilor totalitare.\",\n",
      "          \"page_offset\": 2\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"Pe plan politic, Partidul Comunist unic conducea și controla viața economică și socială a cetățenilor.\",\n",
      "          \"page_offset\": 3\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The textbook narrative presents historical political figures and events with potential bias. For example, the description of the National Liberal Party's continued importance and the influence of key figures like I.I.C. Brătianu may reflect a particular political perspective. The text also frames the development of political life during the interwar period in a way that emphasizes stability and the challenges faced by Romania. Additionally, the portrayal of totalitarian regimes and their impact on citizens' rights may contain value-laden language. The presentation of these historical elements could influence students' interpretations of Romanian history.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Use of primary sources with potentially biased language\",\n",
      "      \"source_type\": \"PRIMARY_SOURCE_USAGE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"„De data aceasta mă adresez grupului celui mai luminat de alegători. (...) Să judecați dumneavoastră voastră. Dacă am făcut ceva pentru acest județ și dacă sunt în stare să mai fac, vă cer voturile în numele dragostei care mă leagă de acest pământ, în numele legăturilor pe care le-au întărit atâtea lupte și atâtea izbânzi.”\",\n",
      "          \"page_offset\": 1\n",
      "        },\n",
      "        {\n",
      "          \"text\": \"„Prin cadrele colhozurilor și sofozurilor s-a început o susținută campanie pentru rusificarea sătenilor. Începutul l-a concretizat prin înființarea de cursuri de limba rusă la care sunt obligați să participe țăranii”\",\n",
      "          \"page_offset\": 3\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The textbook includes primary sources that may contain biased language or reflect the attitudes of their time. For instance, the quote from C. Argoteanu's electoral letter uses emotive language to appeal to voters, which could be seen as reflecting the political rhetoric of the period. Another example is the fragment from a press article discussing the forced Russification of Romanian peasants, which highlights the coercive measures taken during the communist regime. The inclusion of these sources requires careful contextualization to avoid influencing students' interpretations in a non-neutral way.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 2 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 2 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in the presentation of historical political figures and events ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in the presentation of historical political figures and events\n",
      "[DEBUG] Quotes count: 4\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.85, Category=Moral Loading\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Linguistic Tone\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.82, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Narrative Framing, Confidence: 0.82\n",
      "\n",
      "--- Issue 2: Use of primary sources with potentially biased language ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Use of primary sources with potentially biased language\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: PRIMARY_SOURCE_USAGE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.80, Category=Primary Source Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 3\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=1/7, Confidence=0.90, Category=Source Handing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.75, Category=Primary Source Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.82, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Primary Source Framing, Confidence: 0.82\n",
      "\n",
      "============================================================\n",
      "BATCH 21: Pages 101-105\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 101 to 105\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 101:\n",
      "[DEBUG]   - Base64 length: 1,410,152 chars\n",
      "[DEBUG] Added page 102:\n",
      "[DEBUG]   - Base64 length: 1,246,648 chars\n",
      "[DEBUG] Added page 103:\n",
      "[DEBUG]   - Base64 length: 1,295,232 chars\n",
      "[DEBUG] Added page 104:\n",
      "[DEBUG]   - Base64 length: 1,266,036 chars\n",
      "[DEBUG] Added page 105:\n",
      "[DEBUG]   - Base64 length: 1,334,112 chars\n",
      "[DEBUG] Average image size: 1,310,436 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 2763 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\"issues\": [\n",
      "    {\n",
      "        \"controversy\": \"Potential bias in historical interpretation\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"La \\u00afnceputul secolului XX, marea majoritate a europenilor erau convin\\u2193i de necesitatea ca na\\u016diunile \\\"superioare\\\" s\\u0103 domine popoarele inferioare lor.\", \"page_offset\": 0},\n",
      "            {\"text\": \"Astfel de la atitudini au \\u00afncura\\u00f3l imperialism, eliti\\u00f3t, rasist, militarist, agresiv-na\\u016dionalist, \\u00aflate \\u00afnc\\u0103 din vremea constituirii imperiilor coloniale a consolidat \\u00af mai mult aceast\\u0103 opinie.\", \"page_offset\": 0},\n",
      "            {\"text\": \"Majoritatea societ\\u0103\\u016dilor \\u00aflate \\u00afnc\\u0103 o asemeneea stare de spirit aveau economii industriale bine dezvoltate, care le sporeau considerabil capacitatea de lupt\\u0103 distructiv\\u0103.\", \"page_offset\": 0}\n",
      "        ],\n",
      "        \"explanation\": \"The passage could influence interpretation by presenting a potentially biased view of historical events, using loaded language such as 'na\\u016diunile \\\"superioare\\\"' and 'popoarele inferioare lor', which may reflect a particular ideological perspective rather than a neutral historical account.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Loaded language in historical context description\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"Astfel de la atitudini au \\u00afncura\\u00f3l imperialism, eliti\\u00f3t, rasist, militarist, agresiv-na\\u016dionalist, \\u00aflate \\u00afnc\\u0103 din vremea constituirii imperiilor coloniale a consolidat \\u00af mai mult aceast\\u0103 opinie.\", \"page_offset\": 0}\n",
      "        ],\n",
      "        \"explanation\": \"The use of the term 'agresiv-na\\u016dionalist' could be seen as loaded language, potentially influencing the reader's interpretation of historical nationalism.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Perspective on the Treaty of Versailles\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"Toate tratatele de pace au l\\u0103sat loc pentru contesta\\u016dii ulterioare, \\u00afindeosebi ale Germaniei \\u00afnvinse \\u00af umilite dar \\u00af Italiei care n-a primit toate \\\"teritorile revendicate\\\" (Fiume) \\u00af care era dominat\\u0103 de sentimentul \\\"victoriei mutilate\\\".\", \"page_offset\": 2},\n",
      "            {\"text\": \"Unele clauze erau at\\u00e2t de dezechilibrate \\u00afnc\\u00e2t au devenit factori de instabilitate \\u00afn viitorul Europei.\", \"page_offset\": 2}\n",
      "        ],\n",
      "        \"explanation\": \"The description of Germany as 'umilite' and Italy's sentiment of 'victoriei mutilate' presents a particular perspective on the Treaty of Versailles, potentially influencing the reader's understanding of the treaty's impact.\"\n",
      "    }\n",
      "]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 3 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 3 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in historical interpretation ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in historical interpretation\n",
      "[DEBUG] Quotes count: 3\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Language & Framing - Moral Loading\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b succeeded on attempt 3\n",
      "[DEBUG] gpt-oss-120b returned keys: ['final{', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.88, Category=Moral Loading\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.90, Category=Linguistic Tone\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.90, Category=Linguistic Tone\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=Moral Loading\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Moral Loading, Confidence: 0.86\n",
      "\n",
      "--- Issue 2: Loaded language in historical context description ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Loaded language in historical context description\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Language & Framing - Moral Loading\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['final{', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.90, Category=Linguistic Tone\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=4.0/7, Confidence=0.80, Category=Linguistic Tone\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=5.0/7, Confidence=0.90, Category=Moral Loading\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Linguistic Tone\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.78, Flagged=True\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Moral Loading, Confidence: 0.78 ⚠️  [FLAGGED FOR REVIEW]\n",
      "\n",
      "--- Issue 3: Perspective on the Treaty of Versailles ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Perspective on the Treaty of Versailles\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Linguistic Tone\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.90, Category=Perspective Limitation\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.85, Category=Linguistic Tone\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.82, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Perspective Limitation, Confidence: 0.82\n",
      "\n",
      "============================================================\n",
      "BATCH 22: Pages 106-110\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 106 to 110\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 106:\n",
      "[DEBUG]   - Base64 length: 1,415,156 chars\n",
      "[DEBUG] Added page 107:\n",
      "[DEBUG]   - Base64 length: 1,379,520 chars\n",
      "[DEBUG] Added page 108:\n",
      "[DEBUG]   - Base64 length: 1,288,444 chars\n",
      "[DEBUG] Added page 109:\n",
      "[DEBUG]   - Base64 length: 1,310,528 chars\n",
      "[DEBUG] Added page 110:\n",
      "[DEBUG]   - Base64 length: 1,300,084 chars\n",
      "[DEBUG] Average image size: 1,338,746 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 2513 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Loaded language in historical interpretation\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Istoria Societății Națiunilor a fost, într-o mare măsură, istoria interpretării acestui instrument al păcii și a încercărilor de a-l amenda și îmbunătăți.\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The statement implies that the League of Nations was primarily an instrument of peace, which could be seen as a value-laden interpretation rather than a neutral historical fact.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Selective emphasis on historical events\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Ascensiunea regimurilor totalitare, în special a nazismului în Germania și politica conciliatoristă anglo-franceză, au dus la diminuarea rolului Societății Națiunilor și la imposibilitatea de a împiedica politica de forță și dictat impusă de statele totalitare.\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The text focuses on the rise of totalitarian regimes and appeasement policy as key factors in the failure of the League of Nations, which might be seen as selectively emphasizing certain historical interpretations over others.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Framing of historical events\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"Concilierea fusese în trecut un cuvânt onorabil; el a devenit rău famat deoarece, ca și numele politicii occidentale în anii '30, a prelua sensul de a căuta mituirea unei mari puteri expansioniste prin sacrificarea unor mici aliați cărora li se promisese că vor fi apărați.\",\n",
      "          \"page_offset\": 3\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The text frames appeasement negatively by associating it with 'bribery' and failure to protect smaller allies, which could influence the student's interpretation of historical events.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Use of emotive language\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"între 40 și 50 de milioane de morți, la doi-lea război mondial apare drept conflictul cel mai sângeros din istorie.\",\n",
      "          \"page_offset\": 4\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"Describing World War II as 'cel mai sângeros din istorie' (the bloodiest in history) uses emotive language that could influence the student's perception of the event.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 4 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 4 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Loaded language in historical interpretation ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Loaded language in historical interpretation\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Language & Framing - Moral Loading\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.93, Category=Moral Loading\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.70, Category=Linguistic Tone\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Moral Loading, Confidence: 0.86\n",
      "\n",
      "--- Issue 2: Selective emphasis on historical events ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective emphasis on historical events\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.90, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 failed all 3 attempts — DROPPING from council\n",
      "  ✗ DeepSeek-V3.1 dropped (failed validation after 3 attempts)\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.85, Category=Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.90, Category=Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 4\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Selection Bias, Confidence: 0.86\n",
      "\n",
      "--- Issue 3: Framing of historical events ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Framing of historical events\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.92, Category=Moral Loading\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Linguistic Tone\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.90, Category=Moral Loading\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Moral Loading, Confidence: 0.86\n",
      "\n",
      "--- Issue 4: Use of emotive language ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Use of emotive language\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Language & Framing, Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b succeeded on attempt 2\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.96, Category=Linguistic Tone\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Linguistic Tone\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.95, Category=Linguistic Tone\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.90, Category=Linguistic Tone\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.93, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Linguistic Tone, Confidence: 0.93\n",
      "\n",
      "============================================================\n",
      "BATCH 23: Pages 111-115\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 111 to 115\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 111:\n",
      "[DEBUG]   - Base64 length: 1,199,276 chars\n",
      "[DEBUG] Added page 112:\n",
      "[DEBUG]   - Base64 length: 1,142,144 chars\n",
      "[DEBUG] Added page 113:\n",
      "[DEBUG]   - Base64 length: 1,305,100 chars\n",
      "[DEBUG] Added page 114:\n",
      "[DEBUG]   - Base64 length: 1,249,824 chars\n",
      "[DEBUG] Added page 115:\n",
      "[DEBUG]   - Base64 length: 1,282,128 chars\n",
      "[DEBUG] Average image size: 1,235,694 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 4840 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\"issues\": [\n",
      "    {\n",
      "        \"controversy\": \"Value-laden description of historical events\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"În teritoriile dominate de germani s-au folosit mijloace brutale pentru supunerea populației, pentru reprimarea opozițanților și pentru exterminarea celor care apartineau așa-numitelor «rase inferioare» sau considerați «novici» de către ideologia național-socialistă a lui Hitler.\", \"page_offset\": 0},\n",
      "            {\"text\": \"Această tragedie ce a zguduit omenirea secolului XX a rămas cunoscută sub denumirea de «Holocaust» (termen legat de o formă de sacrificiu practicat în antichitate în religiile greacă și ebraică).\", \"page_offset\": 0}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook uses value-laden language when describing the actions of the Germans during WWII, characterizing their methods as 'brutale' and referring to the Holocaust as a 'tragedie ce a zguduit omenirea'. This framing could influence students' interpretation by emphasizing the severity and moral condemnation of these actions.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Selective emphasis on certain historical figures\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"Simon Wiesenthal (1908-2005) Supraviețuitor al Holocaustului, a devenit personaj de legendă. Se apreciază că volumul «Asinii printre noi» (București, Editura politică, 1969) este o chemare la vigilență perpetuă, o demonstrație a necesității menținerii conștiinței treze, pentru ca ororile să nu mai nascâ monștri.\", \"page_offset\": 0},\n",
      "            {\"text\": \"Anne Frank (1929-1945) Fugită cu familia din Frankfurt la Amsterdam, după venirea la putere a lui Adolf Hitler, Anne Frank, o copilă evreică, și-a ținut jurnalul în perioada 1942-1944, când a locuit într-o anexă secretă deasupra biroului tatălui ei. Anne avea 15 ani când a murit în lagărul de la Belsen. Jurnalul său, care conține mărturii din timpul dominației terorii, a arătat lumii o parte din ororile Holocaustului.\", \"page_offset\": 0},\n",
      "            {\"text\": \"Kofi Annan (născut pe 8 aprilie 1938, este al XII-lea secretar-general al Națiunilor Unite\", \"page_offset\": 2},\n",
      "            {\"text\": \"Mahatma Gandhi (1869-1948) Inițiatorul și făptuitorul facto de independenței Indiei, omul care a negociat sfârșitul domniei de 190 de ani a Marii Britanii asupra coloniei sud-asiatice (1947), asasinat de un fanatic religios; «Filosofia nonviolenței și pasivunea pentru independență l-au transformat în omul care a destabilizat colonialismul» (Salman Rushdie, scriitor iranian de origine indiană).\", \"page_offset\": 4}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook selectively highlights certain historical figures associated with significant events or movements (e.g., Holocaust survivors, leaders of international organizations, figures involved in decolonization). The selection and detailed descriptions of these figures could influence students' perception of their importance in history.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Framing of historical events and processes\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"Războiul a declanșat vaste transferări de populație. Sunt evaluate la 30 de milioane persoanele «deplasate» în timpul conflictului.\", \"page_offset\": 0},\n",
      "            {\"text\": \"Conflictuul care s-a scurs s-a manifestat printr-o «strategie a terorii» care lasă mult în urma inovațiile ucigătoare ale anilor 1914-1918 și generează un veritabil șoc moral în anii imediat postbelici.\", \"page_offset\": 0},\n",
      "            {\"text\": \"În 1945, lumea apare profund bulversată. Bazele materiale și culturale s-au năruit, iar psihologia colectivă se însănătoșează cu greu după revelația neașteptată a holocausturilor.\", \"page_offset\": 0}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook frames historical events like WWII and the Holocaust in a way that emphasizes their destructive impact and moral implications. Phrases like 'strategie a terorii' and 'șoc moral' create a specific narrative tone that could influence students' understanding of these events.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Use of primary sources and their interpretation\",\n",
      "        \"source_type\": \"PRIMARY_SOURCE_USAGE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"«Astăzi trăim într-o lume în care un om are mai multe șanse să fie judecat dacă ucide o singură persoană decât dacă ucide 100.000!» (Kofi Annan, 14 iunie 2004, la São Paulo -Brazilia în Le Nouvel Observateur, 3.12.98)\", \"page_offset\": 2}\n",
      "        ],\n",
      "        \"explanation\": \"The inclusion of a quote from Kofi Annan highlights a significant perspective on justice and violence. The way this quote is presented, without additional critical context, could influence students' interpretation of Annan's viewpoint on international justice.\"\n",
      "    }\n",
      "]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 4 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 4 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Value-laden description of historical events ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Value-laden description of historical events\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.95, Category=Moral Loading\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Moral Loading\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.95, Category=Moral Loading\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.90, Category=Moral Loading\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.88, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Moral Loading, Confidence: 0.88\n",
      "\n",
      "--- Issue 2: Selective emphasis on certain historical figures ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective emphasis on certain historical figures\n",
      "[DEBUG] Quotes count: 4\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.86, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.83, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Selection Bias, Confidence: 0.83\n",
      "\n",
      "--- Issue 3: Framing of historical events and processes ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Framing of historical events and processes\n",
      "[DEBUG] Quotes count: 3\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Moral Loading\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Moral Loading\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.90, Category=Moral Loading\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=Moral Loading\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Moral Loading, Confidence: 0.86\n",
      "\n",
      "--- Issue 4: Use of primary sources and their interpretation ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Use of primary sources and their interpretation\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: PRIMARY_SOURCE_USAGE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Primary Source Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 3\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.80, Category=Primary Source Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Primary Source Framing, Confidence: 0.86\n",
      "\n",
      "============================================================\n",
      "BATCH 24: Pages 116-120\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 116 to 120\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 116:\n",
      "[DEBUG]   - Base64 length: 1,262,416 chars\n",
      "[DEBUG] Added page 117:\n",
      "[DEBUG]   - Base64 length: 1,409,376 chars\n",
      "[DEBUG] Added page 118:\n",
      "[DEBUG]   - Base64 length: 1,316,536 chars\n",
      "[DEBUG] Added page 119:\n",
      "[DEBUG]   - Base64 length: 1,416,904 chars\n",
      "[DEBUG] Added page 120:\n",
      "[DEBUG]   - Base64 length: 1,226,884 chars\n",
      "[DEBUG] Average image size: 1,326,423 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 3007 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in historical interpretation\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"Rivalitatea dintre SUA și URSS s-a accentuat în 1946 și 1947, liderii politici americani apreciind că extinderea sferei de influență sovietică în Europa și dincolo de ea putea fi oprită doar prin forță.\", \"page_offset\": 0},\n",
      "        {\"text\": \"Prezența comunistilor în guvernele din Europa Occidentală apărea ca o amenințare în ochii americanilor.\", \"page_offset\": 0},\n",
      "        {\"text\": \"Anul 1947 a fost decisiv în relațiile est-vest: propunerea Planului Marshall de către americani, cu scopul reconstrucției Europei după război, a respinsă de sovietici, și de celelalte state intrate sub influența URSS, și crearea Biroului de Informații Comunist (Cominform), cu scopul întăririi controlului asupră țărilor comuniste din toate țările comuniste.\", \"page_offset\": 0}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook narrative presents the Cold War and its events with a subtle bias towards the Western perspective, particularly American. The language used emphasizes the threat posed by Soviet influence and the defensive measures taken by the Americans, potentially influencing students' interpretation of historical events.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Selective emphasis on certain historical events\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"Primele conflicte Est-Vest din Europa s-au declanșat după terminarea celui de-al doilea război mondial, în condițiile ocupării militare sovietice a statelor devenite satelite ale Uniunii Sovietice: Polonia, România, Bulgaria, Ungaria, Cehoslovacia, Republica Democrată Germană.\", \"page_offset\": 0},\n",
      "        {\"text\": \"Statele arabe au refuzat planul de împărțire a Palestinei propus de ONU și de a recuceri teritoriul ocupat de evrei sau a fugit sau au fost alungați.\", \"page_offset\": 3}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook selectively emphasizes certain events and perspectives, such as the Soviet occupation of Eastern Europe and the Arab-Israeli conflict, potentially creating an imbalance in the historical narrative presented to students.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Use of loaded language\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"terorismul adus moarte și pagube în locuri liniștite, precum centre comerciale și aeroporturi.\", \"page_offset\": 3},\n",
      "        {\"text\": \"grupările teroriste pot fi: pur anarhiste, care promovează violență de dragul violenței, etc.; de inspirație religioasă secte, grupări fundamentaliste, absolutiste, milenariste sau mesianice\", \"page_offset\": 3}\n",
      "      ],\n",
      "      \"explanation\": \"The use of terms like 'terorism' and descriptions of terrorist groups with negative connotations may influence students' perceptions of certain political or religious movements, potentially introducing a bias in their understanding of complex historical and contemporary issues.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 3 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 3 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in historical interpretation ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in historical interpretation\n",
      "[DEBUG] Quotes count: 3\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Language & Framing, Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.88, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=National or Cultural Centering\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.85, Category=Interpretation & Pedagogy\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.84, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.84\n",
      "\n",
      "--- Issue 2: Selective emphasis on certain historical events ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective emphasis on certain historical events\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.92, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 2\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.90, Category=Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.88, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Selection Bias, Confidence: 0.88\n",
      "\n",
      "--- Issue 3: Use of loaded language ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Use of loaded language\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Language & Framing - Moral Loading\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Moral Loading\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=4.0/7, Confidence=0.85, Category=Moral Loading\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.85, Category=Moral Loading\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=True, reasoning=True\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.85, Category=Moral Loading\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.78, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Moral Loading, Confidence: 0.78\n",
      "\n",
      "============================================================\n",
      "BATCH 25: Pages 121-125\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 121 to 125\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 121:\n",
      "[DEBUG]   - Base64 length: 1,415,496 chars\n",
      "[DEBUG] Added page 122:\n",
      "[DEBUG]   - Base64 length: 1,264,152 chars\n",
      "[DEBUG] Added page 123:\n",
      "[DEBUG]   - Base64 length: 1,356,488 chars\n",
      "[DEBUG] Added page 124:\n",
      "[DEBUG]   - Base64 length: 1,264,780 chars\n",
      "[DEBUG] Added page 125:\n",
      "[DEBUG]   - Base64 length: 1,348,552 chars\n",
      "[DEBUG] Average image size: 1,329,893 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 3063 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Framing of NATO's role\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"NATO este principalul instrument al prezenței americane în Europa care trebuie transformat pentru a se evita dispariția sa;\", \"page_offset\": 0},\n",
      "        {\"text\": \"Statele Unite anunta de retragerea trupelor sale din Europa de vest.\", \"page_offset\": 0}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook presents NATO as the principal instrument of American presence in Europe, which could be seen as framing NATO's role in a particular geopolitical context. The mention of the withdrawal of US troops from Western Europe might be interpreted as a significant geopolitical shift.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Globalization description\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"Globalizarea înseamnă și creșterea mobilității și comunicării mai rapide și nesiguranța. Prezența în Europa vizează menținerea unui minimum de stabilitate în relațiile de securitate continentale și conferă Washington-ului 'greutate' în sfere non-militare, precum investițiile și comerțul.\", \"page_offset\": 1},\n",
      "        {\"text\": \"Globalizarea presupune și o redefinire a cetățeniei, cetățenia globală.\", \"page_offset\": 1}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook describes globalization with both positive and negative aspects, which is neutral. However, the emphasis on certain aspects like increased mobility and communication, as well as the redefinition of citizenship, could influence interpretation.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"New centers of power\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"Actualul dezechilibru mondial de putere a fost determinat de dezmembrarea Uniunii Sovietice și de ridicarea economică și militară a altor centre de putere pe glob.\", \"page_offset\": 3},\n",
      "        {\"text\": \"Centrele de putere se definesc pe diverse registre: economic, militaro-strategic și, tot mai mult, cultural-ideologic.\", \"page_offset\": 3}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook discusses the shift in global power dynamics following the dissolution of the Soviet Union and the rise of new power centers. The description of power centers across various domains could influence interpretation of global politics.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Perspective on globalization\",\n",
      "      \"source_type\": \"PRIMARY_SOURCE_USAGE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"„Cred că globalizarea (...) poate fi un factor al bunăstării și are potențialul de a aduce bogăția tuturor, in special celor săraci.”\", \"page_offset\": 2},\n",
      "        {\"text\": \"„Globalizarea (...) are potențialul de a aduce bogăția tuturor, in special celor săraci.”\", \"page_offset\": 2}\n",
      "      ],\n",
      "      \"explanation\": \"The textbook includes primary sources with varying perspectives on globalization, presenting both positive and potentially negative views. The inclusion of diverse viewpoints is generally neutral but could influence interpretation based on the sources selected.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 4 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 4 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Framing of NATO's role ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Framing of NATO's role\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.92, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 3\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.86\n",
      "\n",
      "--- Issue 2: Globalization description ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Globalization description\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.92, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Perspective Limitation\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=Perspective Limitation\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.80, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.82, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Perspective Limitation, Confidence: 0.82\n",
      "\n",
      "--- Issue 3: New centers of power ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: New centers of power\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.86, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=2.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Narrative Framing, Confidence: 0.86\n",
      "\n",
      "--- Issue 4: Perspective on globalization ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Perspective on globalization\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: PRIMARY_SOURCE_USAGE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Perspective & Representation\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=1/7, Confidence=0.95, Category=Primary Source Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Source Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=1/7, Confidence=0.90, Category=Source Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.84, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Primary Source Framing, Confidence: 0.84\n",
      "\n",
      "============================================================\n",
      "BATCH 26: Pages 126-130\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 126 to 130\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 126:\n",
      "[DEBUG]   - Base64 length: 1,305,184 chars\n",
      "[DEBUG] Added page 127:\n",
      "[DEBUG]   - Base64 length: 1,374,976 chars\n",
      "[DEBUG] Added page 128:\n",
      "[DEBUG]   - Base64 length: 1,277,932 chars\n",
      "[DEBUG] Added page 129:\n",
      "[DEBUG]   - Base64 length: 1,331,204 chars\n",
      "[DEBUG] Added page 130:\n",
      "[DEBUG]   - Base64 length: 1,203,560 chars\n",
      "[DEBUG] Average image size: 1,298,571 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 2679 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in historical interpretation\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"La 1900 și mai târziu, elita politică românească, oricare a fost ea, a conștientizat obiective de politică externă fără patronajul uneia sau a mai multora dintre marile puteri.\",\n",
      "          \"page_offset\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The statement implies that Romanian political elites always sought external patronage, potentially oversimplifying complex historical motivations.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Value-laden description of historical events\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"România a fost cel mai activ aliat al Uniunii Sovietice în timpul crizei ungare.\",\n",
      "          \"page_offset\": 3\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The use of 'cel mai activ aliat' could be seen as framing Romania's actions in a potentially biased manner regarding its relationship with the Soviet Union.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Selective emphasis on historical facts\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"În 1948, a fost semnat la Moscova, Tratatul de prietenie și asistență mutuală cu Uniunea Sovietică, tratat ce era valabil 20 de ani și care permitea amestecul sovietic în problemele ce priveau securitatea statului român.\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The emphasis on the treaty's allowance for Soviet interference might be seen as selectively highlighting negative aspects of Romania's historical relations.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Assumptions presented as facts\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"În primii 10 ani de totalitarism comunist (1948–1958), politica externă a României a fost subordonată necondiționat Uniunii Sovietice.\",\n",
      "          \"page_offset\": 1\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The statement assumes a complete subordination without acknowledging potential complexities or nuances in Romania's political stance during that period.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"National alignment cues in historical narrative\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\n",
      "          \"text\": \"România și alte state comuniste, a sprijinit U.R.S.S. în conflictul din Cehoslovacia.\",\n",
      "          \"page_offset\": 3\n",
      "        }\n",
      "      ],\n",
      "      \"explanation\": \"The phrasing might be seen as aligning with a particular national perspective on historical events involving communist states and the Soviet Union.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 5 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 5 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in historical interpretation ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in historical interpretation\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Perspective Limitation\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=4.0/7, Confidence=0.80, Category=Agency Attribution\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.80, Category=Perspective Limitation\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.90, Category=Agency Attribution\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.78, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Perspective Limitation, Confidence: 0.78\n",
      "\n",
      "--- Issue 2: Value-laden description of historical events ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Value-laden description of historical events\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Language & Framing, Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['final{', 'attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.92, Category=Narrative Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Narrative Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=Linguistic Tone\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.86\n",
      "\n",
      "--- Issue 3: Selective emphasis on historical facts ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Selective emphasis on historical facts\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.78, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] DeepSeek-V3.1 succeeded on attempt 3\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.82, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Selection Bias, Confidence: 0.82\n",
      "\n",
      "--- Issue 4: Assumptions presented as facts ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Assumptions presented as facts\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Perspective & Representation\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.92, Category=Perspective Limitation\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Perspective Limitation\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.85, Category=Agency Attribution\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 2/3), retrying...\n",
      "[DEBUG] Valid fields: severity=True, confidence=True, category=False, reasoning=True\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 3\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Perspective Limitation, Confidence: 0.86\n",
      "\n",
      "--- Issue 5: National alignment cues in historical narrative ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: National alignment cues in historical narrative\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=National or Cultural Centering\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=5.0/7, Confidence=0.85, Category=National or Cultural Centering\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.70, Category=National or Cultural Centering\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.80, Category=National or Cultural Centering\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=5.0/7, Confidence=0.90, Category=Perspective Limitation\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=5/7, Confidence=0.78, Flagged=True\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 5/7\n",
      "✓ Saved! Severity: 5/7, Category: Perspective Limitation, Confidence: 0.78 ⚠️  [FLAGGED FOR REVIEW]\n",
      "\n",
      "============================================================\n",
      "BATCH 27: Pages 131-135\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 131 to 135\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 131:\n",
      "[DEBUG]   - Base64 length: 1,236,544 chars\n",
      "[DEBUG] Added page 132:\n",
      "[DEBUG]   - Base64 length: 1,297,624 chars\n",
      "[DEBUG] Added page 133:\n",
      "[DEBUG]   - Base64 length: 1,319,632 chars\n",
      "[DEBUG] Added page 134:\n",
      "[DEBUG]   - Base64 length: 1,217,496 chars\n",
      "[DEBUG] Added page 135:\n",
      "[DEBUG]   - Base64 length: 1,264,276 chars\n",
      "[DEBUG] Average image size: 1,267,114 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 4759 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\"issues\": [\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in presenting religious conflicts\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"Conflicte religioase\", \"page_offset\": 0},\n",
      "        {\"text\": \"1947-1993: Israel, răz-boi între israelieni și pa-lestineni.\", \"page_offset\": 0},\n",
      "        {\"text\": \"1969-1998: Irlanda de Nord, război civil între catolici și protestanți.\", \"page_offset\": 0},\n",
      "        {\"text\": \"1975-1987: Liban, război civil între creștini și musulmani.\", \"page_offset\": 0},\n",
      "        {\"text\": \"1988-1994: Armenia și Azerbaidjan război civil între armenii creștini și azerii musulmani.\", \"page_offset\": 0},\n",
      "        {\"text\": \"1991-1993: Georgia, gherila musulmană.\", \"page_offset\": 0},\n",
      "        {\"text\": \"1991-1993: Georgia, gherila abhază musulmană.\", \"page_offset\": 0},\n",
      "        {\"text\": \"1992-1995: Fosta Iugoslavie, război civil între sârbi ortodocși, croații catolici și musulmani.\", \"page_offset\": 0},\n",
      "        {\"text\": \"1994-1997: Rusia și Cecenia, război între ruși și musulmani.\", \"page_offset\": 0}\n",
      "      ],\n",
      "      \"explanation\": \"The section 'Conflicte religioase' lists various religious conflicts around the world, primarily focusing on conflicts involving Muslims. This selective emphasis on conflicts involving Islam could potentially influence students' perception of the religion and its adherents, possibly reinforcing negative stereotypes or a skewed understanding of religious conflicts.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Potential bias in the presentation of Islam\",\n",
      "      \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"Tentația integrismului\", \"page_offset\": 3},\n",
      "        {\"text\": \"„Îmi place să merg la moschee. Întotdeauna mă simt bine aici... Cum sunt un obiṣnuit al locului, discut adesea cu imamul, care este responsabilul moscheii. Acesta este un bătrân cu barbă albă. Este un imam tânăr. Este reprezentantul tinereii generate care a făcut studiile într-o țară islamică. El este funcționar la ministerului. După el, islamul a prevăzut totul. Totul este să o găsești în islam, chiar și socialismul. El mi-a spus că tara este în pericol deoarece care nu cred în Allah și care sunt plătiți din străinătate vor să conducă țării și să-i închidă pe cei care merg la moschee... El mi-a vorbit mult timp de grupul din care face parte. Sunt unii ca și el care au format un grup de luptă pentru cuvântul lui Allah. Este un grup înarmat cu Coranul și cu pumnale.\\\"\", \"page_offset\": 3},\n",
      "        {\"text\": \"Tentația integrismului musulman\", \"page_offset\": 4},\n",
      "        {\"text\": \"„Pentru mine, Islamul nu a fost niciodată o religie reacționară. Islamul a pledat întotdeauna pentru egalitatea raselor, pentru egalitatea în drepturi a tuturor oamenilor, albi, roșii, galbeni... Islamul a pledat de asemenea pentru libertatea femeii... astăzi când se vorbește, de exemplu de revolutie și de Islam, eu sunt de părere că între ele nu există nici o contradicție.\\\"\", \"page_offset\": 4}\n",
      "      ],\n",
      "      \"explanation\": \"The presentation of Islam includes both a potentially extremist view from 'Tentația integrismului' and a more moderate perspective from a former Algerian president. While the inclusion of diverse viewpoints is educational, the juxtaposition and selection of these particular quotes might influence students' understanding of Islam, potentially reinforcing certain stereotypes or biases if not properly contextualized.\"\n",
      "    },\n",
      "    {\n",
      "      \"controversy\": \"Use of potentially loaded language in historical sources\",\n",
      "      \"source_type\": \"PRIMARY_SOURCE_USAGE\",\n",
      "      \"quotes\": [\n",
      "        {\"text\": \"„Îmi place să merg la moschee. Întotdeauna mă simt bine aici... Cum sunt un obiṣnuit al locului, discut adesea cu imamul, care este responsabilul moscheii. Acesta este un bătrân cu barbă albă. Este un imam tânăr. Este reprezentantul tinereii generate care a făcut studiile într-o țară islamică. El este funcționar la ministerului. După el, islamul a prevăzut totul. Totul este să o găsești în islam, chiar și socialismul. El mi-a spus că tara este în pericol deoarece care nu cred în Allah și care sunt plătiți din străinătate vor să conducă țării și să-i închidă pe cei care merg la moschee... El mi-a vorbit mult timp de grupul din care face parte. Sunt unii ca și el care au format un grup de luptă pentru cuvântul lui Allah. Este un grup înarmat cu Coranul și cu pumnale.\\\"\", \"page_offset\": 3}\n",
      "      ],\n",
      "      \"explanation\": \"The quote from 'Tentația integrismului' reflects an extremist view that could be perceived as promoting a biased or radical interpretation of Islam. While this is a historical source and not the textbook author's narrative, its inclusion without sufficient context or counterbalance might influence students' perceptions of Islam.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 3 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 3 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Potential bias in presenting religious conflicts ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in presenting religious conflicts\n",
      "[DEBUG] Quotes count: 9\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=4.0/7, Confidence=0.90, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=4.0/7, Confidence=0.78, Category=Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=5.0/7, Confidence=0.90, Category=Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.85, Category=Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.85, Category=Selection Bias\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=4/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 4/7\n",
      "✓ Saved! Severity: 4/7, Category: Selection Bias, Confidence: 0.86\n",
      "\n",
      "--- Issue 2: Potential bias in the presentation of Islam ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Potential bias in the presentation of Islam\n",
      "[DEBUG] Quotes count: 4\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Structure & Emphasis\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.78, Category=Source Selection Bias\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=3.0/7, Confidence=0.80, Category=Source Selection Bias\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=4.0/7, Confidence=0.85, Category=Source Selection Bias\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=Primary Source Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.83, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Primary Source Framing, Confidence: 0.83\n",
      "\n",
      "--- Issue 3: Use of potentially loaded language in historical sources ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Use of potentially loaded language in historical sources\n",
      "[DEBUG] Quotes count: 1\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: PRIMARY_SOURCE_USAGE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] gpt-oss-120b succeeded on attempt 2\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.92, Category=Primary Source Framing\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.90, Category=Primary Source Framing\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.85, Category=Primary Source Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.75, Category=Primary Source Framing\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.86, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Primary Source Framing, Confidence: 0.86\n",
      "\n",
      "============================================================\n",
      "BATCH 28: Pages 136-140\n",
      "============================================================\n",
      "Analyzing 5 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 136 to 140\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 136:\n",
      "[DEBUG]   - Base64 length: 1,323,100 chars\n",
      "[DEBUG] Added page 137:\n",
      "[DEBUG]   - Base64 length: 1,409,108 chars\n",
      "[DEBUG] Added page 138:\n",
      "[DEBUG]   - Base64 length: 1,348,724 chars\n",
      "[DEBUG] Added page 139:\n",
      "[DEBUG]   - Base64 length: 1,220,980 chars\n",
      "[DEBUG] Added page 140:\n",
      "[DEBUG]   - Base64 length: 1,157,640 chars\n",
      "[DEBUG] Average image size: 1,291,910 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 2324 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\"issues\": [\n",
      "    {\n",
      "        \"controversy\": \"Religious diversity and national identity\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"Biserica Națională este Biserica unei națiuni care, prin continuitate istorică, reprezintă axa istorică a formării națiunii-stat.\", \"page_offset\": 0},\n",
      "            {\"text\": \"Rolul istoric al BOR nu îi conferă drepturi în plus față de celelalte culte și nu constituie un factor discriminator pentru acestea.\", \"page_offset\": 0}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook discusses the role of the national church in Romanian history and its relation to the formation of the nation-state. The quotes highlight a potential controversy around the concept of a 'national church' and its implications for religious diversity and equality.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Representation of religious practices\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"Pelerinajul nu este un act eminamente creștin. Pentru musulmanii, pelerinajul la Mecca, este unul din cei cinci stâlpi ai islamului.\", \"page_offset\": -1},\n",
      "            {\"text\": \"Hajj este o vizită la Al-Ka'bah, casa lui Allah, odată în viață, de către acei musulmani care-și pot permite să facă călătoria.\", \"page_offset\": -1}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook provides information about religious practices across different faiths, including Christianity and Islam. The representation of these practices could influence students' understanding of religious diversity.\"\n",
      "    },\n",
      "    {\n",
      "        \"controversy\": \"Multiculturalism and religious tolerance\",\n",
      "        \"source_type\": \"TEXTBOOK_NARRATIVE\",\n",
      "        \"quotes\": [\n",
      "            {\"text\": \"Multiculturalitatea este caracteristică a civilizației românești în general.\", \"page_offset\": 0},\n",
      "            {\"text\": \"Practica relațiilor interumane și comunitare relevă faptul că recunoașterea reciprocă nu poate fi instituită nici de o majoritate bisericească, nici de o instituție reprezentativă a diverselor comunități religioase.\", \"page_offset\": 0}\n",
      "        ],\n",
      "        \"explanation\": \"The textbook discusses multiculturalism and religious tolerance in the Romanian context. The quotes highlight the importance of mutual recognition and respect among different religious communities.\"\n",
      "    }\n",
      "]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 3 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "Found 3 potential issue(s)\n",
      "\n",
      "\n",
      "--- Issue 1: Religious diversity and national identity ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Religious diversity and national identity\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=3.0/7, Confidence=0.80, Category=Language & Framing - Narrative Framing\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['final{', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=3.0/7, Confidence=0.85, Category=Group Representation\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.80, Category=Group Representation\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.85, Category=Narrative Framing\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking validation failed (attempt 1/3), retrying...\n",
      "[DEBUG] Valid fields: severity=False, confidence=False, category=False, reasoning=False\n",
      "[DEBUG] Kimi-K2-Thinking succeeded on attempt 2\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.80, Category=National or Cultural Centering\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=3/7, Confidence=0.78, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 3/7\n",
      "✓ Saved! Severity: 3/7, Category: Narrative Framing, Confidence: 0.78\n",
      "\n",
      "--- Issue 2: Representation of religious practices ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Representation of religious practices\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=2.0/7, Confidence=0.90, Category=Group Representation\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=1/7, Confidence=0.95, Category=Group Representation\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=1/7, Confidence=0.90, Category=Group Representation\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=3.0/7, Confidence=0.90, Category=Group Representation\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=3.0/7, Confidence=0.80, Category=Asymmetrical Detail\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.84, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: Narrative Framing, Confidence: 0.84\n",
      "\n",
      "--- Issue 3: Multiculturalism and religious tolerance ---\n",
      "[DEBUG] Calling council for evaluation...\n",
      "[DEBUG] Controversy: Multiculturalism and religious tolerance\n",
      "[DEBUG] Quotes count: 2\n",
      "\n",
      "[DEBUG] ========== STARTING COUNCIL EVALUATION ==========\n",
      "[DEBUG] Model count: 5\n",
      "[DEBUG] Expected source_type: TEXTBOOK_NARRATIVE\n",
      "  > Querying Mixtral-8x7B-Instruct-v0.1...\n",
      "[DEBUG] Mixtral-8x7B-Instruct-v0.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Mixtral-8x7B-Instruct-v0.1: Severity=2.0/7, Confidence=0.80, Category=Perspective & Representation\n",
      "  > Querying gpt-oss-120b...\n",
      "[DEBUG] gpt-oss-120b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ gpt-oss-120b: Severity=2.0/7, Confidence=0.85, Category=Group Representation\n",
      "  > Querying DeepSeek-V3.1...\n",
      "[DEBUG] DeepSeek-V3.1 returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ DeepSeek-V3.1: Severity=2.0/7, Confidence=0.70, Category=National or Cultural Centering\n",
      "  > Querying cogito-v2-1-671b...\n",
      "[DEBUG] cogito-v2-1-671b returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ cogito-v2-1-671b: Severity=2.0/7, Confidence=0.80, Category=Perspective Limitation\n",
      "  > Querying Kimi-K2-Thinking...\n",
      "[DEBUG] Kimi-K2-Thinking returned keys: ['attribution', 'category', 'severity', 'confidence', 'reasoning', '_raw_response']\n",
      "  ✓ Kimi-K2-Thinking: Severity=4.0/7, Confidence=0.85, Category=National or Cultural Centering\n",
      "\n",
      "[DEBUG] ========== CALLING META-JURY ==========\n",
      "[DEBUG] Using model: gpt-5.2\n",
      "[DEBUG] Valid jurors in council: 5\n",
      "[DEBUG] Meta-Jury verdict: Severity=2/7, Confidence=0.78, Flagged=False\n",
      "[DEBUG] ========== COUNCIL COMPLETE ==========\n",
      "[DEBUG] Council evaluation complete: 2/7\n",
      "✓ Saved! Severity: 2/7, Category: National or Cultural Centering, Confidence: 0.78\n",
      "\n",
      "============================================================\n",
      "BATCH 29: Pages 141-144\n",
      "============================================================\n",
      "Analyzing 4 pages together...\n",
      "\n",
      "[DEBUG] ========== STARTING MINER BATCH ==========\n",
      "[DEBUG] PDF: ./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\n",
      "[DEBUG] Processing pages 141 to 144\n",
      "[DEBUG] ===========================================\n",
      "\n",
      "[DEBUG] Added page 141:\n",
      "[DEBUG]   - Base64 length: 823,496 chars\n",
      "[DEBUG] Added page 142:\n",
      "[DEBUG]   - Base64 length: 500,220 chars\n",
      "[DEBUG] Added page 143:\n",
      "[DEBUG]   - Base64 length: 7,412 chars\n",
      "[DEBUG] Added page 144:\n",
      "[DEBUG]   - Base64 length: 196,572 chars\n",
      "[DEBUG] Average image size: 381,925 chars\n",
      "[DEBUG] System prompt length: 3300 chars\n",
      "[DEBUG] Expected JSON format: {\"issues\": [...]}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "\n",
      "[DEBUG] ========== API RESPONSE ==========\n",
      "[DEBUG] Response text length: 14 chars\n",
      "[DEBUG] Full raw response text:\n",
      "{\"issues\": []}\n",
      "[DEBUG] ====================================\n",
      "\n",
      "[DEBUG] Parsed JSON type: <class 'dict'>\n",
      "[DEBUG] Parsed JSON keys: ['issues']\n",
      "[DEBUG] Final count: 0 issues\n",
      "[DEBUG] ========== MINER BATCH COMPLETE ==========\n",
      "[DEBUG] Miner returned empty list for this batch\n",
      "✓ No controversial content found in this batch\n",
      "\n",
      "\n",
      "============================================================\n",
      "PIPELINE COMPLETE\n",
      "Total controversies found: 109\n",
      "Results saved to: results_corvinul_2.jsonl\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def run_pipeline(pdf_path: str, pages_per_batch: int = 10, debug: bool = False):\n",
    "    \"\"\"Main execution loop: Process PDF in batches → Council evaluation.\"\"\"\n",
    "    print(f\"Starting analysis: {pdf_path}\")\n",
    "    print(f\"Batch size: {pages_per_batch} pages\")\n",
    "\n",
    "    total_pages = get_total_pages(pdf_path)\n",
    "    print(f\"Total pages: {total_pages}\\n\")\n",
    "\n",
    "    total_controversies = 0\n",
    "    batch_num = 0\n",
    "\n",
    "    for start_page in range(0, total_pages, pages_per_batch):\n",
    "        batch_num += 1\n",
    "        end_page = min(start_page + pages_per_batch, total_pages)\n",
    "        actual_pages = end_page - start_page\n",
    "\n",
    "        print(f\"\\nBatch {batch_num}  [pages {start_page+1}–{end_page}]\")\n",
    "\n",
    "        controversies = run_miner_batch(pdf_path, start_page, actual_pages, debug=debug)\n",
    "\n",
    "        if not controversies:\n",
    "            print(f\"  No issues found\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  Found {len(controversies)} potential issue(s)\")\n",
    "\n",
    "        for idx, item in enumerate(controversies, 1):\n",
    "            controversy = item.get(\"controversy\", \"Untitled\")\n",
    "            quotes = item.get(\"quotes\", [])\n",
    "            explanation = item.get(\"explanation\", \"\")\n",
    "            source_type = item.get(\"source_type\", \"TEXTBOOK_NARRATIVE\")\n",
    "\n",
    "            print(f\"\\n  Issue {idx}/{len(controversies)}: {controversy}\")\n",
    "\n",
    "            council_result = run_council(controversy, quotes, explanation, source_type, debug=debug)\n",
    "            final_severity = council_result[\"final_severity\"]\n",
    "\n",
    "            result = {\n",
    "                \"batch\": batch_num,\n",
    "                \"pages\": f\"{start_page+1}-{end_page}\",\n",
    "                \"controversy\": controversy,\n",
    "                \"quotes\": quotes,\n",
    "                \"explanation\": explanation,\n",
    "                \"source_type\": source_type,\n",
    "                \"final_severity\": final_severity,\n",
    "                \"system_confidence\": council_result[\"system_confidence\"],\n",
    "                \"final_category\": council_result[\"final_category\"],\n",
    "                \"final_attribution\": council_result[\"final_attribution\"],\n",
    "                \"flagged_for_review\": council_result[\"flag_for_human_review\"],\n",
    "                \"synthesis_reasoning\": council_result[\"synthesis_reasoning\"],\n",
    "                \"variance_analysis\": council_result.get(\"variance_analysis\", \"\"),\n",
    "                \"individual_jurors\": council_result[\"individual_jurors\"]\n",
    "            }\n",
    "\n",
    "            with open(OUTPUT_FILE, 'a', encoding='utf-8') as f:\n",
    "                f.write(json.dumps(result, ensure_ascii=False) + '\\n')\n",
    "\n",
    "            flagged = council_result[\"flag_for_human_review\"]\n",
    "            confidence = council_result[\"system_confidence\"]\n",
    "            category = council_result[\"final_category\"]\n",
    "\n",
    "            severity_str = f\"{final_severity}/7\" if final_severity is not None else \"N/A\"\n",
    "            confidence_str = f\"{confidence:.2f}\" if confidence is not None else \"N/A\"\n",
    "            category_str = category if category is not None else \"N/A\"\n",
    "            flag_str = \" FLAGGED\" if flagged else \"\"\n",
    "\n",
    "            print(f\"  Severity: {severity_str}  Category: {category_str}  Conf: {confidence_str}{flag_str}\")\n",
    "\n",
    "            total_controversies += 1\n",
    "\n",
    "    print(f\"Total: {total_controversies} controversies. Saved to {OUTPUT_FILE}\")\n",
    "\n",
    "\n",
    "run_pipeline(\"./Manuale Istorie/Clasa a 11 a CORVINUL.pdf\", pages_per_batch=5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0453b6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report generated: controversy_report.html\n",
      "109 findings analyzed\n",
      "Average severity: 2.94/7\n",
      "High severity (>=5): 1\n",
      "Flagged for review: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'controversy_report.html'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_html_report(jsonl_file: str, output_html: str = \"controversy_report.html\"):\n",
    "    \"\"\"Generate a clean, readable HTML report.\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    with open(jsonl_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            results.append(json.loads(line, strict=False))\n",
    "    \n",
    "    results.sort(key=lambda x: x.get('final_severity', 0), reverse=True)\n",
    "    \n",
    "    all_categories = sorted(set(r.get('final_category', 'Unknown') for r in results))\n",
    "\n",
    "    total_severity = sum(r.get('final_severity', 0) for r in results)\n",
    "    avg_severity = total_severity / len(results) if results else 0\n",
    "    high_severity_count = sum(1 for r in results if r.get('final_severity', 0) >= 5)\n",
    "    flagged_count = sum(1 for r in results if r.get('flagged_for_review', False))\n",
    "    \n",
    "    html = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Textbook Analysis Report</title>\n",
    "    <style>\n",
    "        * {{\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            box-sizing: border-box;\n",
    "        }}\n",
    "        \n",
    "        body {{\n",
    "            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
    "            line-height: 1.6;\n",
    "            color: #1a1a1a;\n",
    "            background-color: #f8f9fa;\n",
    "            padding: 40px 20px;\n",
    "        }}\n",
    "        \n",
    "        .container {{\n",
    "            max-width: 1000px;\n",
    "            margin: 0 auto;\n",
    "        }}\n",
    "        \n",
    "        h1 {{\n",
    "            color: #2c3e50;\n",
    "            font-size: 2em;\n",
    "            font-weight: 600;\n",
    "            margin-bottom: 30px;\n",
    "            letter-spacing: -0.5px;\n",
    "        }}\n",
    "        \n",
    "        .summary {{\n",
    "            background: white;\n",
    "            padding: 20px;\n",
    "            margin-bottom: 20px;\n",
    "            border-left: 4px solid #2c3e50;\n",
    "            box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        \n",
    "        .summary p {{\n",
    "            margin: 8px 0;\n",
    "            color: #555;\n",
    "        }}\n",
    "        \n",
    "        .summary strong {{\n",
    "            color: #2c3e50;\n",
    "        }}\n",
    "\n",
    "        /* ── Category Filter Bar ── */\n",
    "        .filter-bar {{\n",
    "            background: white;\n",
    "            padding: 16px 20px;\n",
    "            margin-bottom: 24px;\n",
    "            box-shadow: 0 1px 3px rgba(0,0,0,0.08);\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            gap: 12px;\n",
    "            flex-wrap: wrap;\n",
    "        }}\n",
    "\n",
    "        .filter-bar label {{\n",
    "            font-weight: 600;\n",
    "            color: #2c3e50;\n",
    "            font-size: 0.9em;\n",
    "            white-space: nowrap;\n",
    "        }}\n",
    "\n",
    "        .filter-btn {{\n",
    "            padding: 5px 14px;\n",
    "            border: 1px solid #d0d0d0;\n",
    "            border-radius: 20px;\n",
    "            background: #f8f9fa;\n",
    "            color: #444;\n",
    "            font-size: 0.85em;\n",
    "            cursor: pointer;\n",
    "            transition: all 0.15s;\n",
    "            white-space: nowrap;\n",
    "        }}\n",
    "\n",
    "        .filter-btn:hover {{\n",
    "            border-color: #2c3e50;\n",
    "            color: #2c3e50;\n",
    "        }}\n",
    "\n",
    "        .filter-btn.active {{\n",
    "            background: #2c3e50;\n",
    "            border-color: #2c3e50;\n",
    "            color: white;\n",
    "        }}\n",
    "\n",
    "        .filter-count {{\n",
    "            margin-left: auto;\n",
    "            font-size: 0.85em;\n",
    "            color: #888;\n",
    "        }}\n",
    "\n",
    "        .finding {{\n",
    "            background: white;\n",
    "            margin-bottom: 1px;\n",
    "            box-shadow: 0 1px 3px rgba(0,0,0,0.05);\n",
    "            transition: opacity 0.2s;\n",
    "        }}\n",
    "\n",
    "        .finding.hidden {{\n",
    "            display: none;\n",
    "        }}\n",
    "        \n",
    "        .finding-header {{\n",
    "            padding: 20px;\n",
    "            cursor: pointer;\n",
    "            display: flex;\n",
    "            justify-content: space-between;\n",
    "            align-items: center;\n",
    "            user-select: none;\n",
    "            transition: background-color 0.2s;\n",
    "        }}\n",
    "        \n",
    "        .finding-header:hover {{\n",
    "            background-color: #f8f9fa;\n",
    "        }}\n",
    "        \n",
    "        .finding-title {{\n",
    "            color: #2c3e50;\n",
    "            font-weight: 500;\n",
    "            flex: 1;\n",
    "            margin-right: 20px;\n",
    "        }}\n",
    "        \n",
    "        .finding-meta {{\n",
    "            display: flex;\n",
    "            gap: 15px;\n",
    "            align-items: center;\n",
    "        }}\n",
    "        \n",
    "        .finding-score {{\n",
    "            color: #2c3e50;\n",
    "            font-weight: 600;\n",
    "            font-size: 1.1em;\n",
    "        }}\n",
    "        \n",
    "        .finding-category {{\n",
    "            color: #666;\n",
    "            font-size: 0.9em;\n",
    "            background: #f0f0f0;\n",
    "            padding: 4px 8px;\n",
    "            border-radius: 3px;\n",
    "        }}\n",
    "        \n",
    "        .flagged-indicator {{\n",
    "            color: #e74c3c;\n",
    "            font-size: 0.9em;\n",
    "        }}\n",
    "        \n",
    "        .finding-content {{\n",
    "            display: none;\n",
    "            padding: 0 20px 20px 20px;\n",
    "            border-top: 1px solid #f0f0f0;\n",
    "        }}\n",
    "        \n",
    "        .finding.expanded .finding-content {{\n",
    "            display: block;\n",
    "        }}\n",
    "        \n",
    "        .metadata {{\n",
    "            color: #666;\n",
    "            font-size: 0.9em;\n",
    "            margin-bottom: 20px;\n",
    "            padding: 10px;\n",
    "            background: #f8f9fa;\n",
    "            border-radius: 3px;\n",
    "        }}\n",
    "        \n",
    "        .section {{\n",
    "            margin: 20px 0;\n",
    "        }}\n",
    "        \n",
    "        .section-title {{\n",
    "            color: #2c3e50;\n",
    "            font-weight: 600;\n",
    "            margin-bottom: 10px;\n",
    "            font-size: 1em;\n",
    "            text-transform: uppercase;\n",
    "            letter-spacing: 0.5px;\n",
    "        }}\n",
    "        \n",
    "        .explanation {{\n",
    "            background: #f8f9fa;\n",
    "            padding: 15px;\n",
    "            margin: 10px 0;\n",
    "            line-height: 1.7;\n",
    "            border-left: 3px solid #3498db;\n",
    "        }}\n",
    "        \n",
    "        .quote {{\n",
    "            background: #fff9e6;\n",
    "            padding: 12px;\n",
    "            margin: 8px 0;\n",
    "            border-left: 3px solid #f39c12;\n",
    "        }}\n",
    "        \n",
    "        .quote-text {{\n",
    "            color: #1a1a1a;\n",
    "            margin-bottom: 5px;\n",
    "            font-style: italic;\n",
    "        }}\n",
    "        \n",
    "        .quote-page {{\n",
    "            color: #999;\n",
    "            font-size: 0.85em;\n",
    "        }}\n",
    "        \n",
    "        .meta-jury {{\n",
    "            background: #e8f5e9;\n",
    "            padding: 15px;\n",
    "            margin: 15px 0;\n",
    "            border-left: 3px solid #4caf50;\n",
    "        }}\n",
    "        \n",
    "        .meta-jury-title {{\n",
    "            font-weight: 600;\n",
    "            color: #2e7d32;\n",
    "            margin-bottom: 10px;\n",
    "        }}\n",
    "        \n",
    "        .meta-jury-stats {{\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n",
    "            gap: 10px;\n",
    "            margin: 10px 0;\n",
    "        }}\n",
    "        \n",
    "        .meta-stat {{\n",
    "            background: white;\n",
    "            padding: 10px;\n",
    "            border-radius: 3px;\n",
    "        }}\n",
    "        \n",
    "        .meta-stat-label {{\n",
    "            font-size: 0.85em;\n",
    "            color: #666;\n",
    "        }}\n",
    "        \n",
    "        .meta-stat-value {{\n",
    "            font-size: 1.2em;\n",
    "            font-weight: 600;\n",
    "            color: #2e7d32;\n",
    "        }}\n",
    "        \n",
    "        table {{\n",
    "            width: 100%;\n",
    "            border-collapse: collapse;\n",
    "            margin-top: 10px;\n",
    "        }}\n",
    "        \n",
    "        th, td {{\n",
    "            padding: 12px;\n",
    "            text-align: left;\n",
    "            border-bottom: 1px solid #f0f0f0;\n",
    "            font-size: 0.9em;\n",
    "        }}\n",
    "        \n",
    "        th {{\n",
    "            background: #2c3e50;\n",
    "            color: white;\n",
    "            font-weight: 500;\n",
    "        }}\n",
    "        \n",
    "        .model-name {{\n",
    "            color: #2c3e50;\n",
    "            font-weight: 500;\n",
    "        }}\n",
    "        \n",
    "        .severity-badge {{\n",
    "            display: inline-block;\n",
    "            padding: 3px 8px;\n",
    "            border-radius: 3px;\n",
    "            font-weight: 600;\n",
    "            font-size: 0.9em;\n",
    "        }}\n",
    "        \n",
    "        .severity-1, .severity-2 {{\n",
    "            background: #d4edda;\n",
    "            color: #155724;\n",
    "        }}\n",
    "        \n",
    "        .severity-3, .severity-4 {{\n",
    "            background: #fff3cd;\n",
    "            color: #856404;\n",
    "        }}\n",
    "        \n",
    "        .severity-5, .severity-6 {{\n",
    "            background: #f8d7da;\n",
    "            color: #721c24;\n",
    "        }}\n",
    "        \n",
    "        .severity-7 {{\n",
    "            background: #721c24;\n",
    "            color: white;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h1>Textbook Analysis Report — Multi-Dimensional Audit</h1>\n",
    "        \n",
    "        <div class=\"summary\">\n",
    "            <p><strong>Total findings:</strong> {len(results)}</p>\n",
    "            <p><strong>Average severity:</strong> {avg_severity:.2f}/7 (7-point Likert scale)</p>\n",
    "            <p><strong>High severity findings (≥5):</strong> {high_severity_count}</p>\n",
    "            <p><strong>Flagged for human review:</strong> {flagged_count}</p>\n",
    "            <p><strong>Evaluation method:</strong> Multi-dimensional audit with Meta-Jury synthesis</p>\n",
    "        </div>\n",
    "\n",
    "        <!-- Category Filter Bar -->\n",
    "        <div class=\"filter-bar\">\n",
    "            <label>Filter by category:</label>\n",
    "            <button class=\"filter-btn active\" data-filter=\"all\" onclick=\"filterFindings(this)\">All</button>\n",
    "\"\"\"\n",
    "    for cat in all_categories:\n",
    "        cat_js = cat.replace(\"'\", \"\\\\'\")\n",
    "        html += f'            <button class=\"filter-btn\" data-filter=\"{cat_js}\" onclick=\"filterFindings(this)\">{cat}</button>\\n'\n",
    "\n",
    "    html += f\"\"\"            <span class=\"filter-count\" id=\"filter-count\">{len(results)} of {len(results)} shown</span>\n",
    "        </div>\n",
    "\"\"\"\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        severity = result.get('final_severity', 0)\n",
    "        confidence = result.get('system_confidence', 0)\n",
    "        category = result.get('final_category', 'Unknown')\n",
    "        flagged = result.get('flagged_for_review', False)\n",
    "        flag_icon = ' ⚠️' if flagged else ''\n",
    "        \n",
    "        severity_class = f\"severity-{int(severity)}\"\n",
    "        cat_attr = category.replace('\"', '&quot;')\n",
    "        \n",
    "        html += f\"\"\"\n",
    "        <div class=\"finding\" data-category=\"{cat_attr}\" onclick=\"this.classList.toggle('expanded')\">\n",
    "            <div class=\"finding-header\">\n",
    "                <div class=\"finding-title\">{result['controversy']}{flag_icon}</div>\n",
    "                <div class=\"finding-meta\">\n",
    "                    <div class=\"finding-category\">{category}</div>\n",
    "                    <div class=\"finding-score\"><span class=\"severity-badge {severity_class}\">{severity}/7</span></div>\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"finding-content\">\n",
    "                <div class=\"metadata\">\n",
    "                    Pages {result['pages']} | Batch {result['batch']} | System Confidence: {confidence:.2f}\n",
    "                    {' | <span style=\"color: #e74c3c; font-weight: 500;\">⚠️ Flagged for Review</span>' if flagged else ''}\n",
    "                </div>\n",
    "                \n",
    "                <div class=\"section\">\n",
    "                    <div class=\"section-title\">Miner's Analysis</div>\n",
    "                    <div class=\"explanation\">{result['explanation']}</div>\n",
    "                </div>\n",
    "                \n",
    "                <div class=\"section\">\n",
    "                    <div class=\"section-title\">Evidence</div>\n",
    "\"\"\"\n",
    "        \n",
    "        for quote in result['quotes']:\n",
    "            if isinstance(quote, dict):\n",
    "                quote_text = quote.get('text', '')\n",
    "                page_num = quote.get('page', quote.get('page_offset', 'Unknown'))\n",
    "            else:\n",
    "                quote_text = quote\n",
    "                page_num = 'Unknown'\n",
    "            \n",
    "            html += f\"\"\"\n",
    "                    <div class=\"quote\">\n",
    "                        <div class=\"quote-text\">\"{quote_text}\"</div>\n",
    "                        <div class=\"quote-page\">Page: {page_num}</div>\n",
    "                    </div>\n",
    "\"\"\"\n",
    "        \n",
    "        synthesis = result.get('synthesis_reasoning', 'N/A')\n",
    "        variance = result.get('variance_analysis', '')\n",
    "        \n",
    "        html += f\"\"\"\n",
    "                </div>\n",
    "                \n",
    "                <div class=\"section\">\n",
    "                    <div class=\"meta-jury\">\n",
    "                        <div class=\"meta-jury-title\">🏛️ Meta-Jury Final Verdict</div>\n",
    "                        <div class=\"meta-jury-stats\">\n",
    "                            <div class=\"meta-stat\">\n",
    "                                <div class=\"meta-stat-label\">Final Severity</div>\n",
    "                                <div class=\"meta-stat-value\">{severity}/7</div>\n",
    "                            </div>\n",
    "                            <div class=\"meta-stat\">\n",
    "                                <div class=\"meta-stat-label\">System Confidence</div>\n",
    "                                <div class=\"meta-stat-value\">{confidence:.2f}</div>\n",
    "                            </div>\n",
    "                            <div class=\"meta-stat\">\n",
    "                                <div class=\"meta-stat-label\">Category</div>\n",
    "                                <div class=\"meta-stat-value\" style=\"font-size: 1em;\">{category}</div>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                        <p style=\"margin-top: 10px;\"><strong>Synthesis:</strong> {synthesis}</p>\n",
    "                        {f'<p style=\"margin-top: 10px; color: #e74c3c;\"><strong>Variance Analysis:</strong> {variance}</p>' if variance else ''}\n",
    "                    </div>\n",
    "                </div>\n",
    "                \n",
    "                <div class=\"section\">\n",
    "                    <div class=\"section-title\">Individual Juror Evaluations</div>\n",
    "                    <table>\n",
    "                        <thead>\n",
    "                            <tr>\n",
    "                                <th>Juror Model</th>\n",
    "                                <th>Category</th>\n",
    "                                <th>Severity</th>\n",
    "                                <th>Confidence</th>\n",
    "                                <th>Reasoning</th>\n",
    "                            </tr>\n",
    "                        </thead>\n",
    "                        <tbody>\n",
    "\"\"\"\n",
    "        \n",
    "        for juror in result.get('individual_jurors', []):\n",
    "            model_name = juror.get('model', 'Unknown')\n",
    "            juror_severity = juror.get('severity', 'N/A')\n",
    "            juror_confidence = juror.get('confidence', 'N/A')\n",
    "            juror_category = juror.get('category', 'Unknown')\n",
    "            reasoning = juror.get('reasoning', juror.get('error', 'No reasoning'))\n",
    "            \n",
    "            juror_severity_class = f\"severity-{int(float(juror_severity))}\" if isinstance(juror_severity, (int, float)) else \"\"\n",
    "            \n",
    "            html += f\"\"\"\n",
    "                            <tr>\n",
    "                                <td class=\"model-name\">{model_name}</td>\n",
    "                                <td>{juror_category}</td>\n",
    "                                <td><span class=\"severity-badge {juror_severity_class}\">{juror_severity}/7</span></td>\n",
    "                                <td>{juror_confidence if isinstance(juror_confidence, str) else f'{juror_confidence:.2f}'}</td>\n",
    "                                <td>{reasoning}</td>\n",
    "                            </tr>\n",
    "\"\"\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "                        </tbody>\n",
    "                    </table>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "\"\"\"\n",
    "    \n",
    "    html += f\"\"\"\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        function filterFindings(btn) {{\n",
    "            const filter = btn.getAttribute('data-filter');\n",
    "\n",
    "            // Update active button\n",
    "            document.querySelectorAll('.filter-btn').forEach(b => b.classList.remove('active'));\n",
    "            btn.classList.add('active');\n",
    "\n",
    "            // Show/hide findings\n",
    "            const findings = document.querySelectorAll('.finding');\n",
    "            let visibleCount = 0;\n",
    "            findings.forEach(f => {{\n",
    "                if (filter === 'all' || f.getAttribute('data-category') === filter) {{\n",
    "                    f.classList.remove('hidden');\n",
    "                    visibleCount++;\n",
    "                }} else {{\n",
    "                    f.classList.add('hidden');\n",
    "                    // Collapse hidden findings to avoid stale open state\n",
    "                    f.classList.remove('expanded');\n",
    "                }}\n",
    "            }});\n",
    "\n",
    "            document.getElementById('filter-count').textContent =\n",
    "                visibleCount + ' of {len(results)} shown';\n",
    "        }}\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "    \n",
    "    with open(output_html, 'w', encoding='utf-8') as f:\n",
    "        f.write(html)\n",
    "    \n",
    "    print(f\"Report generated: {output_html}\")\n",
    "    print(f\"{len(results)} findings analyzed\")\n",
    "    print(f\"Average severity: {avg_severity:.2f}/7\")\n",
    "    print(f\"High severity (>=5): {high_severity_count}\")\n",
    "    print(f\"Flagged for review: {flagged_count}\")\n",
    "    \n",
    "    return output_html\n",
    "\n",
    "generate_html_report(OUTPUT_FILE)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
